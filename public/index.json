[
{
	"uri": "/3-clbnlbwitheks/3.1-clbnlbwitheksmangednode/",
	"title": "Classic Load Balancer service with Amazon EKS Cluster EC2 Managed NodeGroup",
	"tags": [],
	"description": "",
	"content": "Create Manifest files  Create a directory for CLB section.  cd ..\rmkdir clb\rcd clb Create a file named app-deployment.yaml inside clb.  touch app-deployment.yaml Open file app-deployment.yaml, paste the below code. Then save it. Do not forget to replace \u0026lt;REPLACE-WITH-YOUR-CONTAINER-IMAGE-URL\u0026gt; with your container image URL on DockerHub.  apiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: fcj-app1-deployment\rlabels:\rapp: fcj-app1\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: fcj-app1\rtemplate:\rmetadata:\rlabels:\rapp: fcj-app1\rspec:\rcontainers:\r- name: fcj-app1\rimage: \u0026lt;REPLACE-WITH-YOUR-CONTAINER-IMAGE-URL\u0026gt;\rports:\r- containerPort: 80 In my case, container image URL on DockerHub is firstcloudjourneypcr/fcj-elbeks-workshop-basicapp:v1. You can replace with it for testing purpose.\nCreate a file named ClassicLoadBalancer.yaml inside clb.  touch ClassicLoadBalancer.yaml Open file ClassicLoadBalancer.yaml, paste the below code. Then save it.  apiVersion: v1\rkind: Service\rmetadata:\rname: fcj-app1-clb-svc\rlabels: app: fcj-app1\rspec:\rtype: LoadBalancer # Default - CLB\rselector:\rapp: fcj-app1\rports: - port: 8080\rtargetPort: 8080 Deploy resources  Let create a namespace to deploy resources.  kubectl create ns fcj-app1\rkubectl get ns Execute the below command to deploy resources to fcj-app1 namespace.  kubectl apply -n fcj-app1 -f . List all created resources on fcj-app1 namespace.  kubectl get deploy,pod,svc -n fcj-app1 There are some created resources on fcj-app1 namespace:\n A Deployment named fcj-app1-deployment. A Pod named fcj-app1-deployment-7d9d4f7c44-ddvj8 with STATUS is Running. A Service named fcj-app1-clb-svc with TYPE is LoadBalancer and EXTERNAL-IP is a89ef47f06ea949c2b6e6e91bafc6545-898842507.ap-southeast-1.elb.amazonaws.com.   Let access to Load Balancer. There is a created Load Balancer with Type is classic and DNS name match with EXTERNAL-IP of fcj-app1-clb-svc Service.   Let access to URL http://\u0026lt;YOUR-EXTERNAL-IP\u0026gt;:8080 to see the result.   Your application was deployed with Classic Load Balancer successfully.\nClean up.  Execute the below command to delete all created resources.  kubectl delete -n fcj-app1 -f . List all resources to make sure they are deleted.  kubectl get deploy,pod,svc -n fcj-app1 Delete created namespace.  kubectl delete ns fcj-app1 List all namespace to make sure it is deleted.  kubectl get ns Access to Load Balancer again to verify the created Classic Load Balancer was deleted automatically when fcj-app1-clb-svc Service deleted.   "
},
{
	"uri": "/2-prerequiste/2.1-createcloud9workspace/",
	"title": "Create Cloud9 workspace",
	"tags": [],
	"description": "",
	"content": "Create Cloud9 workspace   Go to Cloud9 at region ap-southeast-1.\n  Click on Create environment.   At Create environment page, input FCJ-Workspace at Name field.\n  Input Workspace for hands on workshop at Description field.\n  At Environment type field, keep default New EC2 instance.\n  At Instance type field, select Additional instance types.\n  At Additional instance types field, select t3.large.   Scroll down to the end of page and click on Create.   The workspace instance is being created.   It will take you about 2 minutes for the instance is created successfully.\n  After the instance is created successfully, click on Open to start your workspace.   "
},
{
	"uri": "/5-dnsingresswitheks/5.1-deployexternaldns/",
	"title": "Deploy ExternalDNS Service",
	"tags": [],
	"description": "",
	"content": "In this section, we will Deploy ExternalDNS Service on Amazon EKS Cluster.\nInspired by Kubernetes DNS, Kubernetes\u0026rsquo; cluster-internal DNS server, ExternalDNS makes Kubernetes resources discoverable via public DNS servers. Like KubeDNS, it retrieves a list of resources (Services, Ingresses, etc.) from the Kubernetes API to determine a desired list of DNS records. Unlike KubeDNS, however, it\u0026rsquo;s not a DNS server itself, but merely configures other DNS providers accordinglyâ€”e.g. AWS Route 53.\nIn a broader sense, ExternalDNS allows you to control DNS records dynamically via Kubernetes resources in a DNS provider-agnostic way.\n Create a new working directory for this section.  mkdir ingress/externaldns Create a new directory to store manifest files for deploying ExternalDNS service.  mkdir ingress/externaldns/externaldns-deployment Create Service Account. Create IAM Policy.  Go to IAM Policy. Click on Create policy.  2. Navigate to JSON tab. 3. Paste the below code to Policy editor. 4. Click on Next.\n{\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;route53:ChangeResourceRecordSets\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:route53:::hostedzone/*\u0026#34;\r]\r},\r{\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;route53:ListHostedZones\u0026#34;,\r\u0026#34;route53:ListResourceRecordSets\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;*\u0026#34;\r]\r}\r]\r} Input AllowExternalDNSUpdates as Name. Input Allow access to Route53 Resources for ExternalDNS as Description. Click on Create policy.  Save the ARN of policy to use later.   Create Service Account.  Create new Namespace for this section.  kubectl create ns fcj-external-dns-ingress-ns\rkubectl get ns fcj-external-dns-ingress-ns Create Service Account on created Namespace. Replace with your created Policy Arn.  eksctl create iamserviceaccount \\\r--name external-dns \\\r--namespace fcj-external-dns-ingress-ns \\\r--cluster fcj-elb-cluster \\\r--region ap-southeast-1 \\\r--attach-policy-arn \u0026lt;REPLACE-WITH-YOUR-CREATED-POLICY-ARN\u0026gt; \\\r--approve \\\r--override-existing-serviceaccounts List created Service Account.  kubectl get sa external-dns -n fcj-external-dns-ingress-ns Verify that IAM Service Account is created.  eksctl get iamserviceaccount --cluster fcj-elb-cluster --region ap-southeast-1 Save the ROLE ARN of IAM Service Account external-dns to use later.\nCreate ExternalDNS manifest file.  Create a file named 01-Deploy-ExternalDNS.yaml inside ingress/externaldns/externaldns-deployment.  touch ingress/externaldns/externaldns-deployment/01-Deploy-ExternalDNS.yaml\rls ingress/externaldns/externaldns-deployment Open file 01-Deploy-ExternalDNS.yaml, paste the below code. Replace with your created IAM Service Account external-dns Arn. Then save it.  apiVersion: v1\rkind: ServiceAccount\rmetadata:\rname: external-dns\r# If you\u0026#39;re using Amazon EKS with IAM Roles for Service Accounts, specify the following annotation.\r# Otherwise, you may safely omit it.\rannotations:\r# Substitute your account ID and IAM service role name below. #Change-1: Replace with your IAM ARN Role for extern-dns\reks.amazonaws.com/role-arn: \u0026lt;REPLACE-WITH-YOUR-IAM-SERVICE-ACCOUNT-ARN\u0026gt;\r---\rapiVersion: rbac.authorization.k8s.io/v1\rkind: ClusterRole\rmetadata:\rname: external-dns\rrules:\r- apiGroups: [\u0026#34;\u0026#34;]\rresources: [\u0026#34;services\u0026#34;,\u0026#34;endpoints\u0026#34;,\u0026#34;pods\u0026#34;]\rverbs: [\u0026#34;get\u0026#34;,\u0026#34;watch\u0026#34;,\u0026#34;list\u0026#34;]\r- apiGroups: [\u0026#34;extensions\u0026#34;,\u0026#34;networking.k8s.io\u0026#34;]\rresources: [\u0026#34;ingresses\u0026#34;]\rverbs: [\u0026#34;get\u0026#34;,\u0026#34;watch\u0026#34;,\u0026#34;list\u0026#34;]\r- apiGroups: [\u0026#34;\u0026#34;]\rresources: [\u0026#34;nodes\u0026#34;]\rverbs: [\u0026#34;list\u0026#34;,\u0026#34;watch\u0026#34;]\r---\rapiVersion: rbac.authorization.k8s.io/v1\rkind: ClusterRoleBinding\rmetadata:\rname: external-dns-viewer\rroleRef:\rapiGroup: rbac.authorization.k8s.io\rkind: ClusterRole\rname: external-dns\rsubjects:\r- kind: ServiceAccount\rname: external-dns\rnamespace: fcj-external-dns-ingress-ns\r---\rapiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: external-dns\rspec:\rstrategy:\rtype: Recreate\rselector:\rmatchLabels:\rapp: external-dns\rtemplate:\rmetadata:\rlabels:\rapp: external-dns spec:\rserviceAccountName: external-dns\rcontainers:\r- name: external-dns\rimage: k8s.gcr.io/external-dns/external-dns:v0.10.2\rargs:\r- --source=service\r- --source=ingress\r- --provider=aws\r- --aws-zone-type=public # only look at public hosted zones (valid values are public, private or no value for both)\r- --registry=txt\r- --txt-owner-id=my-hostedzone-identifier\rsecurityContext:\rfsGroup: 65534 # For ExternalDNS to be able to read Kubernetes and AWS token files Deploy ExternalDNS  Execute the below command to deploy ExternalDNS.  kubectl apply -f ingress/externaldns/externaldns-deployment -n fcj-external-dns-ingress-ns List all resources on Namespace fcj-external-dns-ingress-ns.  kubectl get all -n fcj-external-dns-ingress-ns "
},
{
	"uri": "/",
	"title": "Deploy Load Balancer Service on Amazon EKS",
	"tags": [],
	"description": "",
	"content": "Deploy Load Balancer Service on Amazon EKS Overview This workshop will provide a high level overview on how to integrate Load Balancer Service for application that run on Amazon EKS Cluster with Class Load Balancer, Application Load Balancer (Ingress Service) and Network Load Balancer.\nAdditionally, we will integrate Load Balancer Service with Domain Name System (DNS) Service via Route 53 and secure your traffic by AWS Certificate Manager.\nContent  Introduction Prerequisites Classic Load Balancer service with Amazon EKS Cluster Ingress service with Amazon EKS Cluster (Optional) Integrate ExternalDNS Service for Amazon EKS Cluster Network Load Balancer service with Amazon EKS Cluster Cleanup resources  "
},
{
	"uri": "/4-ingresswitheks/4.1-installlbc/",
	"title": "Install AWS Load Balancer Controller",
	"tags": [],
	"description": "",
	"content": "AWS Load Balancer Controller is a controller to help manage Elastic Load Balancers for a Kubernetes cluster. The controller can provision the following resources:\n An AWS Application Load Balancer when you create a Kubernetes Ingress. An AWS Network Load Balancer or Classic Load Balancer when you create a Kubernetes Service of type LoadBalancer.  To integrate your Application Pod on EC2 Managed Nodegroup with Ingress (Application Load Balanber) and Route53 Service. It\u0026rsquo;s necessary to have alb-ingress-access, full-ecr-access and external-dns-access access permission. To do that, we will delete current Nodegroup and create another new with those accesses.\nDelete current NodeGroup  Execute the below command to delete current EC2 Managed NodeGroup.  eksctl delete nodegroup --cluster fcj-elb-cluster --region ap-southeast-1 --name fcj-elb-nodegroup --disable-eviction  It will take you about 5 minutes to finish.   List all Nodes in your Cluster to make sure it was deleted.\n  kubectl get nodes Create a new NodeGroup  Execute the below command to create new EC2 Managed NodeGroup with alb-ingress-access, full-ecr-access and external-dns-access access permission.  eksctl create nodegroup --cluster fcj-elb-cluster --region ap-southeast-1 --name fcj-ingress-nodegroup --managed --nodes=1 --node-type=t3.large --alb-ingress-access --full-ecr-access --external-dns-access --node-private-networking  It will take you about 5 minutes to finish.   List your created Node.\n  kubectl get nodes -o wide Create IAM Policy In this step, we will create IAM policy for the AWS Load Balancer Controller that allows it to make calls to AWS APIs on your behalf.\n At Cloud9 Terminal, download IAM Policy.  curl -o iam_policy_latest.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/main/docs/install/iam_policy.json Create IAM Policy using policy downloaded.  aws iam create-policy --policy-name AWSLoadBalancerControllerIAMPolicy --policy-document file://iam_policy_latest.json Make a note of Policy ARN as we are going to use that in next step when creating IAM Role.  Create an IAM Role for the AWS LoadBalancer Controller and attach the Role to the Kubernetes Service Account.  Verify if any existing service account.  kubectl get sa aws-load-balancer-controller -n kube-system There is no created Service Account named aws-load-balancer-controller on Namespace kube-system on your Cluster.\nCreate IAM Role. Replace with your Policy ARN.  eksctl create iamserviceaccount \\\r--cluster=fcj-elb-cluster \\\r--region=ap-southeast-1 \\\r--namespace=kube-system \\\r--name=aws-load-balancer-controller \\\r--attach-policy-arn=\u0026lt;REPACE-WITH-YOUR-POLICY-ARN\u0026gt; \\\r--override-existing-serviceaccounts \\\r--approve Verify that there ia a created service account named aws-load-balancer-controller on Namespace kube-system on your Cluster.  Let describe the service account for more detail.  kubectl describe sa aws-load-balancer-controller -n kube-system  At Annotations field, we can see there is a IAM Role Arn associated with the Service Account. Let copy the IAM Role name.   Access to IAM Role and search with IAM Role name to see the result.   There is an IAM Role created and associated to your Service Account automatically when you created it.\nInstall the AWS Load Balancer Controller In this step, we will install the AWS Load Balancer Controller by using Helm.\n Install Helm.  curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 \u0026gt; get_helm.sh\rchmod 700 get_helm.sh\r./get_helm.sh Check Helm version.  helm version Install the AWS Load Balancer Controller with Helm. Replace with your Cluster\u0026rsquo;s VPC ID.  # Add the eks-charts repository.\rhelm repo add eks https://aws.github.io/eks-charts\r# Update your local repo to make sure that you have the most recent charts.\rhelm repo update\r# Install the AWS Load Balancer Controller.\rhelm install aws-load-balancer-controller eks/aws-load-balancer-controller \\\r-n kube-system \\\r--set clusterName=fcj-elb-cluster \\\r--set serviceAccount.create=false \\\r--set serviceAccount.name=aws-load-balancer-controller \\\r--set region=ap-southeast-1 \\\r--set vpcId=\u0026lt;REPLACE-WITH-CLUSTER-VPC-ID\u0026gt; \\\r--set image.repository=602401143452.dkr.ecr.ap-southeast-1.amazonaws.com/amazon/aws-load-balancer-controller Verify that the controller is installed and Webhook Service created  kubectl -n kube-system get deployment aws-load-balancer-controller\rkubectl -n kube-system get svc aws-load-balancer-webhook-service\rkubectl get pods -n kube-system There are some created resources:\n A created Deployment named aws-load-balancer-controller. A created Webhook Service named aws-load-balancer-webhook-service. Two created Pods named aws-load-balancer-controller-xxxxxxxxxx-xxxxx.  Let describe a created Pod to see that the AWS_ROLE_ARN parameter is generated IAM Role ARN when you create Service Account.  You had installed the AWS Load Balancer Controller successful.\nCreate Ingress Class  Create a new working directory for this section.  cd ~\rcd environment\rmkdir ingress Create a new directory to store ingress class manifest file.  mkdir ingress/ingress-class\rls ingress Create a manifest file named ingress-class.yaml inside ingress/ingress-class.  touch ingress/ingress-class/ingress-class.yaml\rls ingress/ingress-class/ Open file ingress-class.yaml, paste the below code. Then save it.  apiVersion: networking.k8s.io/v1\rkind: IngressClass\rmetadata:\rname: my-aws-ingress-class\rannotations:\ringressclass.kubernetes.io/is-default-class: \u0026#34;true\u0026#34;\rspec:\rcontroller: ingress.k8s.aws/alb Execute the below command to create Ingress Class.  kubectl apply -f ingress/ingress-class List your created Ingress Class.  kubectl get ingressclass There is a created Ingress Class named my-aws-ingress-class.\nDescribe your created Ingress Class.  kubectl describe ingressclass my-aws-ingress-class "
},
{
	"uri": "/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Overview Classic Load Balancer provides basic load balancing across multiple Amazon EC2 instances and operates at both the request level and connection level. Classic Load Balancer is intended for applications that are built within the EC2-Classic network.\nApplication Load Balancer operates at the request level (layer 7), routing traffic to targets (EC2 instances, containers, IP addresses, and Lambda functions) based on the content of the request. Ideal for advanced load balancing of HTTP and HTTPS traffic, Application Load Balancer provides advanced request routing targeted at delivery of modern application architectures, including microservices and container-based applications. Application Load Balancer simplifies and improves the security of your application, by ensuring that the latest SSL/TLS ciphers and protocols are used at all times.\nNetwork Load Balancer operates at the connection level (Layer 4), routing connections to targets (Amazon EC2 instances, microservices, and containers) within Amazon VPC, based on IP protocol data. Ideal for load balancing of both TCP and UDP traffic, Network Load Balancer is capable of handling millions of requests per second while maintaining ultra-low latencies. Network Load Balancer is optimized to handle sudden and volatile traffic patterns while using a single static IP address per Availability Zone. It is integrated with other popular AWS services such as Auto Scaling, Amazon EC2 Container Service (ECS), Amazon CloudFormation, and AWS Certificate Manager (ACM).\nRoute 53 is a highly available and scalable Domain Name System (DNS) web service. Route 53 connects user requests to internet applications running on AWS or on-premises.\nAWS Certificate Manager helps to provision, manage, and deploy public and private SSL/TLS certificates for use with AWS services and your internal connected resources. ACM removes the time-consuming manual process of purchasing, uploading, and renewing SSL/TLS certificates.\nContent  Introduction Prerequisites Classic Load Balancer service with Amazon EKS Cluster Ingress service with Amazon EKS Cluster (Optional) Integrate ExternalDNS Service for Amazon EKS Cluster Network Load Balancer service with Amazon EKS Cluster Cleanup resources  "
},
{
	"uri": "/6-nlbwitheks/6.1-nlbwitheksmanagednode/",
	"title": "Network Load Balancer service with Amazon EKS Cluster EC2 Managed Node",
	"tags": [],
	"description": "",
	"content": "Deploy Basic Network Load Balancer service with Amazon EKS Cluster EC2 Managed Node Create Manifest file.  Create new directory for this section.  mkdir nlb\rls Create new working directory.  mkdir nlb/ManagedNodeGroup\rls nlb Copy manifest file named app-deployment.yaml from clb/ManagedNodeGroup/ to nlb/ManagedNodeGroup.  cp clb/ManagedNodeGroup/app-deployment.yaml nlb/ManagedNodeGroup\rls nlb/ManagedNodeGroup Create a new file named NetworkLoadBalancer.yaml inside nlb/ManagedNodeGroup.  touch nlb/ManagedNodeGroup/NetworkLoadBalancer.yaml\rls nlb/ManagedNodeGroup Open file NetworkLoadBalancer.yaml, paste the code below and save it.  apiVersion: v1\rkind: Service\rmetadata:\rname: fcj-basic-nlb-service\rannotations:\r# Traffic Routing\rservice.beta.kubernetes.io/aws-load-balancer-name: fcj-basic-nlb\rservice.beta.kubernetes.io/aws-load-balancer-type: external\r# Health Check Settings\rservice.beta.kubernetes.io/aws-load-balancer-healthcheck-protocol: http\rservice.beta.kubernetes.io/aws-load-balancer-healthcheck-port: traffic-port\rservice.beta.kubernetes.io/aws-load-balancer-healthcheck-path: /\rservice.beta.kubernetes.io/aws-load-balancer-healthcheck-healthy-threshold: \u0026#34;3\u0026#34;\rservice.beta.kubernetes.io/aws-load-balancer-healthcheck-unhealthy-threshold: \u0026#34;3\u0026#34;\rservice.beta.kubernetes.io/aws-load-balancer-healthcheck-interval: \u0026#34;10\u0026#34; # Access Control\rservice.beta.kubernetes.io/load-balancer-source-ranges: 0.0.0.0/0 service.beta.kubernetes.io/aws-load-balancer-scheme: \u0026#34;internet-facing\u0026#34;\rspec:\rtype: LoadBalancer\rselector:\rapp: fcj-app1\rports:\r- port: 80\rtargetPort: 80 Deploy resources.  Execute the below command to deploy resources on Namespace fcj-external-dns-ingress-ns.  kubectl apply -f nlb/ManagedNodeGroup -n fcj-external-dns-ingress-ns\rkubectl get all -n fcj-external-dns-ingress-ns There are some created resources:\n A created Deployment named fcj-app1-deployment with replicas is 1. A created ReplicaSet named fcj-app1-deployment-xxxxxxxxxx with replicas is 1. A created Pod named fcj-app1-deployment-xxxxxxxxxx-xxxxx with STATUS is Running. A created Service named fcj-basic-nlb-service with Type is LoadBalancer and EXTERNAL-IP is fcj-basic-nlb-b85e5b7a2c14c0d3.elb.ap-southeast-1.amazonaws.com.   Let access to Load Balancer. There is a created Load Balancer with Type is network and DNS name match with EXTERNAL-IP of fcj-basic-nlb-service Service.   Click on your Load Balancer to verify the Listeners. When we access to application via TCP:8080, it will be forwarded to created TargetGroup.   Click on to created TargetGroup to verify the Registered targets.   The Registered targets is the EC2 Managed Node on your Cluster with Health status is Healthy.\nVerify the result.  Access to your application URL http://\u0026lt;YOUR-NETWORK-LOAD-BALANCER-URL\u0026gt;:8080.   (Optional) Integrate with ExternalDNS service. Modify Manifest file.  Open file NetworkLoadBalancer.yaml, add the below annotations to integrate with ExternalDNS service. Then save it.  # External DNS - For creating a Record Set in Route53\rexternal-dns.alpha.kubernetes.io/hostname: fcjnlb.\u0026lt;YOUR-DOMAIN-NAME\u0026gt; Deploy resources.  Execute the below command to redeploy resources on Namespace fcj-external-dns-ingress-ns.  kubectl apply -f nlb/ManagedNodeGroup -n fcj-external-dns-ingress-ns\rkubectl get all -n fcj-external-dns-ingress-ns The Service named fcj-basic-nlb-service will be configured.\nVerify result.  Access to http://fcjnlb.\u0026lt;YOUR-DOMAIN-NAME\u0026gt;:8080 to verify the result.  Clean up.  Delete the created resources.  kubectl delete -f nlb/ManagedNodeGroup -n fcj-external-dns-ingress-ns\rkubectl get all -n fcj-external-dns-ingress-ns We will retain resources which related to external-dns service and created SSL certificate on AWS Certificate Manager for next sections.\nAccess to Load Balancer to verify that the created Network Load Balancer deleted automatically when Service fcj-basic-nlb-service was deleted.   "
},
{
	"uri": "/3-clbnlbwitheks/3.2-clbnlbwitheksfargate/",
	"title": "Classic Load Balancer service with Amazon EKS Cluster Fargate Profile",
	"tags": [],
	"description": "",
	"content": " Move all resources of previous section to a new directory named ManagedNodeGroup.  mkdir ManagedNodeGroup\rmv app-deployment.yaml ManagedNodeGroup/\rmv ClassicLoadBalancer.yaml ManagedNodeGroup/\rls ManagedNodeGroup Create new directory named Fargate for this section.  mkdir Fargate Create Fargate Profile  Move to Fargate directory and create directory named FargateProfile.  cd Fargate\rmkdir FargateProfile Create a file name fargate-profiles.yml inside FargateProfile.  touch FargateProfile/fargate-profiles.yml Open file fargate-profiles.yml, paste the below code. Then save it.  apiVersion: eksctl.io/v1alpha5\rkind: ClusterConfig\rmetadata:\rname: fcj-elb-cluster #Cluster Name\rregion: ap-southeast-1 # Region ID\rfargateProfiles:\r- name: fp-app1\rselectors:\r- namespace: ns-fcj-fp To create Fargate Profile, you need to create namespace which match with provided fargateProfiles.selectors.namespace parameter value on fargate-profiles.yml manifest file.  kubectl create ns ns-fcj-fp List your created namespace.  kubectl get ns Create Fargate Profile.  eksctl create fargateprofile -f FargateProfile/fargate-profiles.yml List created Fargate Profile.  eksctl get fargateprofile --cluster fcj-elb-cluster --region ap-southeast-1 -o yaml Create Manifest file We will re-use the Manifest files in previous section.\n Create a folder name kube-manifest.  mkdir kube-manifest Copy all manifest files of ManagedNodeGroup to Fargate/kube-manifest.  cd ..\rcp -r ManagedNodeGroup/* Fargate/kube-manifest\rcd Fargate\rls kube-manifest Deploy resources  Execute the below command to deploy resources on namespace ns-fcj-fp which defined on Fargate Profile.  kubectl apply -n ns-fcj-fp -f kube-manifest List all created resources. It will take about 3 minutes for all resources created successfully.  kubectl get -n ns-fcj-fp deploy,pod,svc There are some created resources on fcj-app1 namespace:\n A Deployment named fcj-app1-deployment. A Pod named fcj-app1-deployment-7d9d4f7c44-lbqc6 with STATUS is Running. A Service named fcj-app1-clb-svc with TYPE is LoadBalancer and EXTERNAL-IP is a40e3cb6afdf84f60b8b8064284ad7cf-785887277.ap-southeast-1.elb.amazonaws.com.   Let access to Load Balancer. There is a created Load Balancer with Type is classic and DNS name match with EXTERNAL-IP of fcj-app1-clb-svc Service.   Let access to URL http://\u0026lt;YOUR-EXTERNAL-IP\u0026gt;:8080 to see the result.   Your application was deployed with Classic Load Balancer successfully.\nLet list all running Nodes in your Cluster.  kubectl get nodes We has 2 types of Worker Node here. One belongs to EC2 Managed Node Group with name format ip-\u0026lt;PRIVATE-IP\u0026gt;.ap-southeast-1.compute.internal and the other belongs to Fargate Profile with name format fargate-ip-\u0026lt;PRIVATE-IP\u0026gt;.ap-southeast-1.compute.internal. Let take note the name of Fargate Profile \u0026rsquo;s Node, we will describe the Application Pod to see which Node it is placing.\nList your Application Pod again to get the Pod Name.  kubectl get -n ns-fcj-fp pod Let describe your Pod.  kubectl describe -n ns-fcj-fp pod \u0026lt;REPLACE-WITH-POD-NAME\u0026gt; Let compare your Fargate Profile \u0026rsquo;s Node Name and value of Node field to verify that they are match.\nCongratulations, you had deployed application and integrated with Classic Load Balancer on Fargate Node successfully! Clean up  Execute the below command to delete your created resources on namespace ns-fcj-fp.  kubectl delete -n ns-fcj-fp -f kube-manifest List all resources to make sure they are deleted.  kubectl get deploy,pod,svc -n ns-fcj-fp  Access to Load Balancer again to verify the created Classic Load Balancer was deleted automatically when fcj-app1-clb-svc Service deleted.   Delete created Fargate Profile. It will take you about 5 minutes to finish.\n  eksctl delete fargateprofile --name fp-app1 --cluster fcj-elb-cluster --region ap-southeast-1 --wait List Fargate Profile to make sure it is deleted.  eksctl get fargateprofile --cluster fcj-elb-cluster --region ap-southeast-1 -o yaml Delete created Namespace.  kubectl delete ns ns-fcj-fp List all namespace to make sure it is deleted.  kubectl get ns "
},
{
	"uri": "/4-ingresswitheks/4.2-basciingress/",
	"title": "Create Basic Ingress",
	"tags": [],
	"description": "",
	"content": "In the previous section, you had installed the AWS Load Balancer Controller and created an Ingress Class. In this section, we will create a basic Ingress to integrate with our application.\nCreate Manifest files  Create a new working directory for this section.  mkdir ingress/basic-ingress Create a manifest file named 01-App1-Deployment.yaml to deploy your application.  touch ingress/basic-ingress/01-App1-Deployment.yaml Open file 01-App1-Deployment.yaml, paste the below code. Then save it. Don\u0026rsquo;t forget to replace with your container image URL or you can use firstcloudjourneypcr/fcj-elbeks-workshop-basicapp:v1 for testing purpose.  apiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: fcj-app1-deployment\rlabels:\rapp: fcj-app1\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: fcj-app1\rtemplate:\rmetadata:\rlabels:\rapp: fcj-app1\rspec:\rcontainers:\r- name: fcj-app1\rimage: \u0026lt;REPLACE-WITH-YOUR-CONTAINER-IMAGE-URL\u0026gt;\rports:\r- containerPort: 8080 Create a file named 02-NodePort-svc.yaml to create NodePort for Application Pod.  touch ingress/basic-ingress/02-NodePort-svc.yaml Open file 02-NodePort-svc.yaml, paste the below code. Then save it.  apiVersion: v1\rkind: Service\rmetadata:\rname: fcj-app1-nodeport-service\rlabels:\rapp: fcj-app1\rspec:\rtype: NodePort\rselector:\rapp: fcj-app1\rports:\r- port: 8080\rtargetPort: 8080 Create a file named 03-ALB-ingress.yaml to create and integrate ALB Ingress Service to your application.  touch ingress/basic-ingress/03-ALB-ingress.yaml Open file 03-ALB-ingress.yaml, paste the below code. Then save it.  apiVersion: networking.k8s.io/v1\rkind: Ingress\rmetadata:\rname: fcj-app1-ingress\rlabels:\rapp: fcj-app1\rannotations:\r# Load Balancer Name\ralb.ingress.kubernetes.io/load-balancer-name: app1ingressrules\r# Ingress Core Settings\ralb.ingress.kubernetes.io/scheme: internet-facing\r# Health Check Settings\ralb.ingress.kubernetes.io/healthcheck-protocol: HTTP alb.ingress.kubernetes.io/healthcheck-port: traffic-port\ralb.ingress.kubernetes.io/healthcheck-path: / alb.ingress.kubernetes.io/healthcheck-interval-seconds: \u0026#39;15\u0026#39;\ralb.ingress.kubernetes.io/healthcheck-timeout-seconds: \u0026#39;5\u0026#39;\ralb.ingress.kubernetes.io/success-codes: \u0026#39;200\u0026#39;\ralb.ingress.kubernetes.io/healthy-threshold-count: \u0026#39;2\u0026#39;\ralb.ingress.kubernetes.io/unhealthy-threshold-count: \u0026#39;2\u0026#39;\rspec:\ringressClassName: my-aws-ingress-class # Ingress Class\rrules:\r- http:\rpaths:\r- path: /\rpathType: Prefix\rbackend:\rservice:\rname: fcj-app1-nodeport-service\rport:\rnumber: 8080 Deploy resources.  First, create a new Namespace named fcj-basic-ingress-ns to deploy resources for this section.  kubectl create ns fcj-basic-ingress-ns List your created Namespace.  kubectl get ns List all resources on Namespace fcj-basic-ingress-ns to make sure there are no resources created on it.  kubectl get ingress,deploy,svc,pod -n fcj-basic-ingress-ns Go to Load Balancers to verify there is no ALB created.  Now, let create the resources on Namespace fcj-basic-ingress-ns.  kubectl apply -f ingress/basic-ingress -n fcj-basic-ingress-ns List your created resources.  kubectl get ingress,deploy,svc,pod -n fcj-basic-ingress-ns There are some created resources:\n A created Ingress named fcj-app1-ingress with Class is my-aws-ingress-class, ADDRESS is app1ingressrules-2077624863.ap-southeast-1.elb.amazonaws.com and PORTS is 80. A created Deployment named fcj-app1-deployment. A created Service named fcj-app1-nodeport-service with TYPE is NodePort. A created Pod named fcj-app1-deployment-xxxxxxxxxx-xxxxx.  Go to Load Balancers to see the result.   The Application Load Balancer named fcj-app1-ingress, with Type is application, is created automatically when the Ingress created.\nWait to State of Application Load Balancer named fcj-app1-ingress change to Active. Click on it.   There is a Listener. Click on it.   There is a Target Group routed by Path Pattern /. Click on it.   The application was deploy on EC2 Instance of Node Group with Port number and Health status is Healthy.   Let verify the result by accessing to your application URL http://\u0026lt;REPLACE-WITH-YOUR-INGRESS-ADDRESS\u0026gt;.\n  Congratulations, you had deploy your application and integrate with Ingress (AWS Application Load Balancer) Service successfully. Clean up.  Execute the below command to delete resources on Namespace fcj-basic-ingress-ns.  kubectl delete -f ingress/basic-ingress -n fcj-basic-ingress-ns List all resources again to make sure they are deleted.  kubectl get ingress,deploy,svc,pod -n fcj-basic-ingress-ns Delete Namespace fcj-basic-ingress-ns.  kubectl delete ns fcj-basic-ingress-ns Make sure that it is deleted.  kubectl get ns fcj-basic-ingress-ns Go to Load Balancers to verify the Application Load Balancer deleted automatically when Ingress deleted.   "
},
{
	"uri": "/2-prerequiste/2.2-modifyiamrole/",
	"title": "Modify IAM role",
	"tags": [],
	"description": "",
	"content": "In this step, we will create a IAM Role and assign it to workspace instance.\nCreate IAM role   Click IAM to navigate to IAM service.\n  Click on Role.\n  Click on Create role.   At Trusted entity type field, select AWS service.\n  At Service or use case field, select EC2.   Then, click on Next.   At Permissions policies field, select policy name AdministratorAccess.   Then, click on Next.   At Name, review, and create page, input eksworkspace-administrator at Role name field.   Then, scroll down to the end of page and click on Create role.   Assign role to workspace instance   At AWS Cloud9 interface, click on Manage EC2 instance.   You will see the created workspace instance. Then, click to select it.\n  Click on Action.\n  Click on Security.\n  Click on Modify IAM role.   Select the role name eksworkspace-administrator which was created at above steps.\n  Then, click on Update IAM role.   New IAM role was updated successfully.   Update Cloud9 configuration Cloud9 will manage IAM credentials automatically. This default configuration is currently not compatible with EKS authentication via IAM, we will need to disable this feature and use the IAM Role.\n\r  At AWS Cloud9 interface, click on AWS Cloud9.\n  Select Preferences.   At AWS Settings, disable AWS managed temporary credentials.   To ensure that temporary credentials are not saved in Cloud9, we will delete all existing credentials with the command below.\n  rm -vf ${HOME}/.aws/credentials "
},
{
	"uri": "/6-nlbwitheks/6.2-nlbwitheksfargate/",
	"title": "Network Load Balancer service with Amazon EKS Cluster Fargate Node",
	"tags": [],
	"description": "",
	"content": "Deploy Basic Network Load Balancer service with Amazon EKS Cluster Fargate Node Modify Manifest file. Because the Fargate Profile was created in the previous section, so we will re-use it. Let add labels is runon: Fargate to our application manifest files.\n  Open file named app-deployment.yaml inside nlb/ManagedNodeGroup. Add labels is runon: Fargate at metadata.labels and spec.template.metadata.labels parameter. Then save it.   Open file named NetworkLoadBalancer.yaml inside nlb/ManagedNodeGroup. Add labels is runon: Fargate at metadata parameter. Additionally, toggle to comment the definition of External DNS at line 26. Then save it.   Deploy resources.  Deploy resources on Namespace fcj-external-dns-ingress-ns.  kubectl apply -f nlb/ManagedNodeGroup -n fcj-external-dns-ingress-ns List created resources on Namespace fcj-external-dns-ingress-ns.  kubectl get all -n fcj-external-dns-ingress-ns 3. List all Nodes in your Cluster.\nkubectl get node -o wide There are a created Fargate Instance for application.\nLet describe your Pod to verify it is running on Fargate Instance. Replace with Pod ID and verify that the IP of Pod match with INTERNAL-IP of Fargate Instance and Node of Pod is the name of Fargate Instance.  kubectl describe pod \u0026lt;POD-ID\u0026gt; -n fcj-external-dns-ingress-ns Access to Load Balancer to verify that the created Network Load Balancer.   Verify the result.  Access to your application URL http://\u0026lt;YOUR-NETWORK-LOAD-BALANCER-URL\u0026gt;:8080.   The application works!\n(Optional) Integrate with ExternalDNS service. Modify Manifest file.  Open file NetworkLoadBalancer.yaml, uncomment ExternalDNS definition at line 26 and replace with fcjnlbfargate.\u0026lt;YOUR-DOMAIN-NAME\u0026gt;. Then save it.  Redeploy resources.  Execute the below command to redeploy resources on Namespace fcj-external-dns-ingress-ns.  kubectl apply -f nlb/ManagedNodeGroup -n fcj-external-dns-ingress-ns\rkubectl get all -n fcj-external-dns-ingress-ns The Service named fcj-basic-nlb-service will be configured.\nVerify result.  Access to http://fcjnlbfargate.\u0026lt;YOUR-DOMAIN-NAME\u0026gt;:8080 to verify the result.   Clean up Delete created resources.  Delete your created resources on Namespace fcj-external-dns-ingress-ns.  kubectl delete -f nlb/ManagedNodeGroup -n fcj-external-dns-ingress-ns\rkubectl get all -n fcj-external-dns-ingress-ns Delete ExternalDNS Service  Delete ExternalDNS Service on Namespace fcj-external-dns-ingress-ns.  kubectl delete -f ingress/externaldns/externaldns-deployment -n fcj-external-dns-ingress-ns\rkubectl get all -n fcj-external-dns-ingress-ns Delete created Namespace.  Delete created Namespace fcj-external-dns-ingress-ns.  kubectl delete ns fcj-external-dns-ingress-ns\rkubectl get ns fcj-external-dns-ingress-ns Congratulations, you had deploy your application to Amazon EKS Cluster on Fargate Node with Ingress and ExternalDNS service successfully. "
},
{
	"uri": "/2-prerequiste/",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": "Overview To conduct the lab, we have to prepare the Cloud9 workspace instance and create the IAM role for the Cloud9 instance.\nContent  2.1 Create Cloud9 workspace 2.2 Modify IAM Role 2.3 Installation 2.4 Create Amazon EKS Cluster 2.5 Create application  "
},
{
	"uri": "/5-dnsingresswitheks/5.2-useexternaldnsasingress/",
	"title": "Use ExternalDNS as Ingress Service",
	"tags": [],
	"description": "",
	"content": "Create Manifest files.  Create a new working directory.  mkdir ingress/externaldns/externaldns-ingress\rls ingress/externaldns Copy all resources on ingress/context-based-routing-ingress to ingress/externaldns/externaldns-ingress.  cp ingress/context-based-routing-ingress/* ingress/externaldns/externaldns-ingress\rls ingress/externaldns/externaldns-ingress Open file 05-ALB-ingress.yaml, add the below annotation. Replace with your DNS Name.  # External DNS - For creating a Record Set in Route53\rexternal-dns.alpha.kubernetes.io/hostname: \u0026lt;REPLACE-WITH-YOUR-DNSNAME\u0026gt; Deploy resources.  Deploy resources on Namespace fcj-external-dns-ingress-ns.  kubectl apply -f ingress/externaldns/externaldns-ingress -n fcj-external-dns-ingress-ns Get all created resources on Namespace fcj-external-dns-ingress-ns.  kubectl get all -n fcj-external-dns-ingress-ns Access to Route53 click to your Host Zone to verify there is a new DNS Record firstcloudjourney created.  Verify the result.   Access to http://\u0026lt;YOUR-DNS-NAME\u0026gt;/app1.   Access to http://\u0026lt;YOUR-DNS-NAME\u0026gt;/app2.   Congratulations, you had deployed your application with DNS Name successfully. Clean up.  Delete the created resources.  kubectl delete -f ingress/externaldns/externaldns-ingress -n fcj-external-dns-ingress-ns\rkubectl get all -n fcj-external-dns-ingress-ns We will retain resources which related to external-dns service for next sections.\nGo to Route53 click to your Host Zone to verify the created DNS Record firstcloudjourney deleted automatically when Ingress Service deleted.   "
},
{
	"uri": "/3-clbnlbwitheks/",
	"title": "Classic Load Balancer service with Amazon EKS Cluster",
	"tags": [],
	"description": "",
	"content": "Overview In this section, we will create a Classic Load Balancer, which Amazon EKS Cluster wil integrate with, to expose public traffic to Application Pod on Private Subnet. Content  3.1. Classic Load Balancer service with Amazon EKS Cluster EC2 Managed NodeGroup 3.2. Classic Load Balancer service with Amazon EKS Cluster Fargate Profile  "
},
{
	"uri": "/4-ingresswitheks/4.3-conextbasedroutingingress/",
	"title": "Context Path Based Routing Ingress on EC2 Managed NodeGroup",
	"tags": [],
	"description": "",
	"content": "We are going to deploy all these 2 apps in kubernetes with context path based routing enabled in Ingress Controller:\n /app1/* - should go to application App1. /app2/* - should go to application App2.  Create Manifest files.  Create a new working directory for this section.  mkdir ingress/context-based-routing-ingress Create a filed name 01-App1-Deployment.yaml inside ingress/context-based-routing-ingress.  touch ingress/context-based-routing-ingress/01-App1-Deployment.yaml Open file 01-App1-Deployment.yaml, paste the below code. Then save it. We will use container image URL stacksimplify/kube-nginxapp1:1.0.0 for testing purpose.  apiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: fcj-app1-deployment\rlabels:\rapp: fcj-app1\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: fcj-app1\rtemplate:\rmetadata:\rlabels:\rapp: fcj-app1\rspec:\rcontainers:\r- name: fcj-app1\rimage: stacksimplify/kube-nginxapp1:1.0.0\rports:\r- containerPort: 80 Create a filed name 02-App1-NodePort-svc.yaml inside ingress/context-based-routing-ingress.  touch ingress/context-based-routing-ingress/02-App1-NodePort-svc.yaml Open file 02-App1-NodePort-svc.yaml, paste the below code. Then save it.  apiVersion: v1\rkind: Service\rmetadata:\rname: fcj-app1-nodeport-service\rlabels:\rapp: fcj-app1\rannotations: alb.ingress.kubernetes.io/healthcheck-path: /app1/index.html\rspec:\rtype: NodePort\rselector:\rapp: fcj-app1\rports:\r- port: 80\rtargetPort: 80 Create a filed name 03-App2-Deployment.yaml inside ingress/context-based-routing-ingress.  touch ingress/context-based-routing-ingress/03-App1-Deployment.yaml Open file 03-App2-Deployment.yaml, paste the below code. Then save it. We will use container image URL stacksimplify/kube-nginxapp2:1.0.0 for testing purpose.  apiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: fcj-app2-deployment\rlabels:\rapp: fcj-app2\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: fcj-app2\rtemplate:\rmetadata:\rlabels:\rapp: fcj-app2\rspec:\rcontainers:\r- name: fcj-app2\rimage: stacksimplify/kube-nginxapp2:1.0.0\rports:\r- containerPort: 80 Create a filed name 04-App2-NodePort-svc.yaml inside ingress/context-based-routing-ingress.  touch ingress/context-based-routing-ingress/04-App2-NodePort-svc.yaml Open file 04-App2-NodePort-svc.yaml, paste the below code. Then save it.  apiVersion: v1\rkind: Service\rmetadata:\rname: fcj-app2-nodeport-service\rlabels:\rapp: fcj-app2\rannotations: alb.ingress.kubernetes.io/healthcheck-path: /app2/index.html\rspec:\rtype: NodePort\rselector:\rapp: fcj-app2\rports:\r- port: 80\rtargetPort: 80 Create a filed name 05-ALB-ingress.yaml inside ingress/context-based-routing-ingress.  touch ingress/context-based-routing-ingress/05-ALB-ingress.yaml Open file 05-ALB-ingress.yaml, paste the below code. Then save it.  apiVersion: networking.k8s.io/v1\rkind: Ingress\rmetadata:\rname: fcj-context-based-routing-ingress\rannotations:\r# Load Balancer Name\ralb.ingress.kubernetes.io/load-balancer-name: fcj-context-based-routing\r# Ingress Core Settings\ralb.ingress.kubernetes.io/scheme: internet-facing\r# Health Check Settings\ralb.ingress.kubernetes.io/healthcheck-protocol: HTTP alb.ingress.kubernetes.io/healthcheck-port: traffic-port\ralb.ingress.kubernetes.io/healthcheck-interval-seconds: \u0026#39;15\u0026#39;\ralb.ingress.kubernetes.io/healthcheck-timeout-seconds: \u0026#39;5\u0026#39;\ralb.ingress.kubernetes.io/success-codes: \u0026#39;200\u0026#39;\ralb.ingress.kubernetes.io/healthy-threshold-count: \u0026#39;2\u0026#39;\ralb.ingress.kubernetes.io/unhealthy-threshold-count: \u0026#39;2\u0026#39;\rspec:\ringressClassName: my-aws-ingress-class # Ingress Class\rrules:\r- http:\rpaths:\r- path: /app1\rpathType: Prefix\rbackend:\rservice:\rname: fcj-app1-nodeport-service\rport:\rnumber: 80\r- path: /app2\rpathType: Prefix\rbackend:\rservice:\rname: fcj-app2-nodeport-service\rport:\rnumber: 80 Deploy resources.  Create new Namespace to deploy resources on.  kubectl create ns fcj-context-based-routing-ns List created Namespace.  kubectl get ns fcj-context-based-routing-ns Deploy resources on created Namespace.  kubectl apply -f ingress/context-based-routing-ingress -n fcj-context-based-routing-ns List created resources.  kubectl get ingress,svc,deploy,pod -n fcj-context-based-routing-ns There are some created resources:\n A created Ingress named fcj-context-based-routing-ingress with ADDRESS is fcj-context-based-routing-1220596484.ap-southeast-1.elb.amazonaws.com. Two created Service named fcj-app1-nodeport-service and fcj-app2-nodeport-service for Application App1 and App2. Two created Deploymet named fcj-app1-deployment and fcj-app2-deployment, and two created Pod for each Application.   Go to Load Balancers to verify that there is a Application Load Balancer created automatically.   Verify Listener Rule of Application Load Balancer. There are two created rules: One for App1 and one for App2.   Access to your Ingress Address to verify the result:\n   Access with /app1 to go to Application App1. Access with /app2 to go to Application App2.   Clean up  Execute the below command to delete resources on Namespace fcj-context-based-routing-ns.  kubectl delete -f ingress/context-based-routing-ingress -n fcj-context-based-routing-ns List all resources again to make sure they are deleted.  kubectl get ingress,svc,deploy,pod -n fcj-context-based-routing-ns Delete Namespace fcj-context-based-routing-ns.  kubectl delete ns fcj-context-based-routing-ns Make sure that it is deleted.  kubectl get ns fcj-context-based-routing-ns Go to Load Balancers to verify the Application Load Balancer deleted automatically when Ingress deleted.   "
},
{
	"uri": "/2-prerequiste/2.3-installation/",
	"title": "Installation",
	"tags": [],
	"description": "",
	"content": "In this workshop, we will install necessary tools: awscli, kubectl and eksctl.\nUpgrade awscli  Copy and paste the command below into Terminal of Cloud9 Workspace to upgrade awscli.  sudo pip install --upgrade awscli \u0026amp;\u0026amp; hash -r Install kubectl  At Cloud9 Terminal, execute those command to install kubectl.   Update the instance packages.  sudo yum update  Install kubectl.  curl -LO https://dl.k8s.io/release/v1.30.0/bin/linux/amd64/kubectl sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl Check version of kubectl.  kubectl version --client Install eksctl  At Cloud9 terminal, execute those command to install eksctl.   Download and extract the latest release of eksctl with the following command.  curl --silent --location \u0026#34;https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz\u0026#34; | tar xz -C /tmp  Move the extracted binary to /usr/local/bin.  sudo mv /tmp/eksctl /usr/local/bin  Test that your installation was successful with the following command  eksctl version "
},
{
	"uri": "/5-dnsingresswitheks/5.3-namebasedvirtualhostrouting/",
	"title": "Name Based Virtual Host Routing",
	"tags": [],
	"description": "",
	"content": "In this section, we will implement Host Header routing using Ingress.\nCreate Manifest files.  Create new working directory for this section.  mkdir ingress/externaldns/host-header-routing-ingress\rls ingress/externaldns We will re-use the resources of previous section. Let copy all resources inside ingress/externaldns/externaldns-ingress to ingress/externaldns/host-header-routing-ingress.  cp ingress/externaldns/externaldns-ingress/* ingress/externaldns/host-header-routing-ingress\rls ingress/externaldns/host-header-routing-ingress Open file 05-ALB-ingress.yaml, delete all its definitions and replace with the below code. Then, replace \u0026lt;REPLACE-WITH-YOUR-HOST-HEADER-APP1\u0026gt; and \u0026lt;REPLACE-WITH-YOUR-HOST-HEADER-APP2\u0026gt; with your Host Header of each application.  apiVersion: networking.k8s.io/v1\rkind: Ingress\rmetadata:\rname: fcj-host-header-based-routing-ingress\rannotations:\r# Load Balancer Name\ralb.ingress.kubernetes.io/load-balancer-name: fcj-host-header-based-routing\r# Ingress Core Settings\ralb.ingress.kubernetes.io/scheme: internet-facing\r# Health Check Settings\ralb.ingress.kubernetes.io/healthcheck-protocol: HTTP alb.ingress.kubernetes.io/healthcheck-port: traffic-port\ralb.ingress.kubernetes.io/healthcheck-interval-seconds: \u0026#39;15\u0026#39;\ralb.ingress.kubernetes.io/healthcheck-timeout-seconds: \u0026#39;5\u0026#39;\ralb.ingress.kubernetes.io/success-codes: \u0026#39;200\u0026#39;\ralb.ingress.kubernetes.io/healthy-threshold-count: \u0026#39;2\u0026#39;\ralb.ingress.kubernetes.io/unhealthy-threshold-count: \u0026#39;2\u0026#39;\rspec:\ringressClassName: my-aws-ingress-class # Ingress Class\rrules:\r- host: \u0026lt;REPLACE-WITH-YOUR-HOST-HEADER-APP1\u0026gt;\rhttp:\rpaths:\r- path: /\rpathType: Prefix\rbackend:\rservice:\rname: fcj-app1-nodeport-service\rport:\rnumber: 80\r- host: \u0026lt;REPLACE-WITH-YOUR-HOST-HEADER-APP2\u0026gt;\rhttp:\rpaths:\r- path: /\rpathType: Prefix\rbackend:\rservice:\rname: fcj-app2-nodeport-service\rport:\rnumber: 80 Deploy resources.  Deploy resources on Namespace fcj-external-dns-ingress-ns.  kubectl apply -f ingress/externaldns/host-header-routing-ingress -n fcj-external-dns-ingress-ns List all created resources.  kubectl get all -n fcj-external-dns-ingress-ns Access to Route53 click to your Host Zone to verify there are two new DNS Records firstcloudjourney-app1 and firstcloudjourney-app2 created.   Verify the result.   Access to http://firstcloudjourney-app1.\u0026lt;YOUR-DNS-NAME\u0026gt;/app1.   When you access to http://firstcloudjourney-app1.\u0026lt;YOUR-DNS-NAME\u0026gt;/app2. The returned result will be fail.   Access to http://firstcloudjourney-app2.\u0026lt;YOUR-DNS-NAME\u0026gt;/app2.   When you access to http://firstcloudjourney-app2.\u0026lt;YOUR-DNS-NAME\u0026gt;/app1. The returned result will be fail.   Congratulations, you had deployed your application with DNS Name Based Virtual Host Routing successfully. Clean up.  Delete the created resources.  kubectl delete -f ingress/externaldns/host-header-routing-ingress -n fcj-external-dns-ingress-ns\rkubectl get all -n fcj-external-dns-ingress-ns We will retain resources which related to external-dns service for next sections.\nGo to Route53 click to your Host Zone to verify the created DNS Records firstcloudjourney-app1 and firstcloudjourney-app2 deleted automatically when Ingress Service deleted.   "
},
{
	"uri": "/4-ingresswitheks/4.4-ingresswithfargate/",
	"title": "Context Path Based Routing Ingress on Fargate Profile",
	"tags": [],
	"description": "",
	"content": "In previous section, we deployed all these 2 apps in kubernetes with context path based routing with Ingress Controller on EC2 Managed Node. In this section, we are going to deploy them on Fargate Profile.\nCreate Manifest file  Create new working directory for this section.  mkdir ingress/context-based-routing-ingress-on-fargate Create Fargate Profile manifest file.  mkdir ingress/context-based-routing-ingress-on-fargate/fargate-profile\rls ingress/context-based-routing-ingress-on-fargate\rtouch ingress/context-based-routing-ingress-on-fargate/fargate-profile/fargate-profile.yaml\rls ingress/context-based-routing-ingress-on-fargate/fargate-profile Open file fargate-profile.yaml, paste the code below. Then save it.  apiVersion: eksctl.io/v1alpha5\rkind: ClusterConfig\rmetadata:\rname: fcj-elb-cluster\rregion: ap-southeast-1\rspec:\r- name: fcj-fp\rselectors:\r- namespace: fcj-context-path-based-routing-fargate-ns Create a new folder to store application manifest files.  mkdir ingress/context-based-routing-ingress-on-fargate/application\rls ingress/context-based-routing-ingress-on-fargate Copy all application manifest files on previous section inside ingress/context-based-routing-ingress to ingress/context-based-routing-ingress-on-fargate/application.  cp ingress/context-based-routing-ingress/* ingress/context-based-routing-ingress-on-fargate/application\rls ingress/context-based-routing-ingress-on-fargate/application Deploy resource Create namespace to deploy resources on.  Create the namespace named fcj-context-path-based-routing-fargate-ns, matched with value of parameter spec.selectors.namespace on ingress/context-based-routing-ingress-on-fargate/fargate-profile/fargate-profile.yaml.  kubectl create ns fcj-context-path-based-routing-fargate-ns List your created Namespace.  kubectl get ns fcj-context-path-based-routing-fargate-ns Create Fargate Profile.  Get the current Fargate Profile on EKS Cluster.  eksctl get fargateprofile --cluster fcj-elb-cluster --region ap-southeast-1 Create Fargate Profile on your EKS Cluster.  eksctl create fargateprofile -f ingress/context-based-routing-ingress-on-fargate/fargate-profile/fargate-profile.yaml 3.List Fargate Profile on EKS Cluster again.\neksctl get fargateprofile --cluster fcj-elb-cluster --region ap-southeast-1 Deploy resources.  Execute the below command to deploy resources on Namespace fcj-context-path-based-routing-fargate-ns.  kubectl apply -f ingress/context-based-routing-ingress-on-fargate/application -n fcj-context-path-based-routing-fargate-ns List you created resources.  kubectl get ingress,svc,deploy,pod -n fcj-context-path-based-routing-fargate-ns There are some created resources:\n A created Ingress named fcj-context-based-routing-ingress with ADDRESS is fcj-context-based-routing-427025104.ap-southeast-1.elb.amazonaws.com. Two created Service named fcj-app1-nodeport-service and fcj-app2-nodeport-service for Application App1 and App2. Two created Deploymet named fcj-app1-deployment and fcj-app2-deployment, and two created Pod for each Application.  Let list your current Node to verify that Fargate Node created.  kubectl get node -o wide There are two created Fargate Node.\nVerify the result.  Access to http://\u0026lt;REPLACE-WITH-INGRESS-ADDRESS\u0026gt;/app1 to verify the result.  Access to http://\u0026lt;REPLACE-WITH-INGRESS-ADDRESS\u0026gt;/app2 to verify the result.  Congratulations, you had deploy your application with Ingress Service to Fargate Node successfully. Clean up.  Execute the below command to delete created resources.  kubectl delete -f ingress/context-based-routing-ingress-on-fargate/application -n fcj-context-path-based-routing-fargate-ns\rkubectl get ingress,svc,deploy,pod -n fcj-context-path-based-routing-fargate-ns All of them are deleted.\nDelete the Fargate Profile.  eksctl delete fargateprofile --name fcj-fp --cluster fcj-elb-cluster --region ap-southeast-1 --wait\reksctl get fargateprofile --cluster fcj-elb-cluster --region ap-southeast-1 Delete the created Namespace.  kubectl delete ns fcj-context-path-based-routing-fargate-ns\rkubectl get ns fcj-context-path-based-routing-fargate-ns Verify that Fargate Nodes are deleted.  kubectl get node -o wide There is only an EC2 Managed Node.\nGo to Load Balancers to verify the Application Load Balancer deleted automatically when Ingress deleted.   "
},
{
	"uri": "/2-prerequiste/2.4-createekscluster/",
	"title": "Create Amazon EKS Cluster",
	"tags": [],
	"description": "",
	"content": "In previous step, we installed necessary tools: awscli, kubectl and eksctl. Now, we will process to create an Amazon EKS Cluster with managed Node Group as EC2 Instance.\nCreate Amazon EKS Cluster.  At Cloud9 terminal, execute the command the below to create an Amazon EKS Cluster.  eksctl create cluster --name=fcj-elb-cluster --region=ap-southeast-1 --zones=ap-southeast-1a,ap-southeast-1b --without-nodegroup Then, verify the Cluster by command.  eksctl get cluster --region=ap-southeast-1 Enable kubectl to communicate with your cluster by adding a new context to the kubectl config file.  aws eks update-kubeconfig --region=ap-southeast-1 --name=fcj-elb-cluster Then, confirm communication with your cluster by running the following command.  kubectl get svc Note: The expected output is the appearance of ClusterIP service.\nCreate and associate IAM OIDC Provider for EKS Cluster. IAM OpenID Connect (OIDC) Provider help to use some Amazon EKS add-ons, or to enable individual Kubernetes workloads to have specific AWS Identity and Access Management (IAM) permissions.\n At Cloud9 terminal, execute the command the below to create and associate an OIDC Provider to your Amazon EKS Cluster.  eksctl utils associate-iam-oidc-provider --cluster=fcj-elb-cluster --region=ap-southeast-1 --approve To confirm created OIDC Provider, go to IAM. Navigate to Identity providers section. You will see there is a new Provider had been created.  Create Amazon EKS Private Managed Node Group.  At Cloud9 terminal, execute the command the below to create a Managed Node Group in Private Subnet and associate it to EKS Cluster.  eksctl create nodegroup --name=fcj-elb-nodegroup --cluster=fcj-elb-cluster --region=ap-southeast-1 --node-type=t3.medium --nodes=1 --node-private-networking  It will take you about 15 minutes to finish this process.   List existing nodes in cluster.\n  kubectl get nodes -o wide There is no EXTERNAL-IP assigned to your Node.\n"
},
{
	"uri": "/4-ingresswitheks/",
	"title": "Ingress service with Amazon EKS Cluster",
	"tags": [],
	"description": "",
	"content": "Overview When you create a Kubernetes ingress, an AWS Application Load Balancer (ALB) is provisioned that load balances application traffic, ALBs can be used with Pods that are deployed to nodes or to AWS Fargate. You can deploy an ALB to public or private subnets. Content  4.1 Install AWS Load Balancer Controller 4.2 Create Basic Ingress 4.3 Context Path Based Routing Ingress 4.4 Context Path Based Routing Ingress on Fargate Profile  "
},
{
	"uri": "/5-dnsingresswitheks/5.4-sslandssldirect/",
	"title": "SSL and SSL Redirect",
	"tags": [],
	"description": "",
	"content": "In this section, we will create a SSL certificate for application. Then, redirect all HTTP traffics to HTTPS port.\nIntegrate SSL certificate to your application. Create a SSL Certificate in Certificate Manager   Go to AWS Certificate Manager. Click on Request a certificate.   At Request certificate, click on Next.   Input domain name with format *.\u0026lt;YOUR-DOMAIN-NAME\u0026gt; at Fully qualified domain name field.   Keep default at another fields. Then click on Request.   Your Certificate is created but in Pending validation status.   Let create a new record in Route53 for validation. Click on Create records in Route 53.   Click on Create records.   Go to Route 53, click on your Host Zone to see there is a new record created by AWS Certificate Manager.   Back to AWS Certificate Manager to see the status your created Certificate changed to Issued.\n  It will take about 10 minutes to validate successful.\n\rSave the ARN to use later.   Create Manifest files.  Create new working directory for this section.  mkdir ingress/externaldns/ssl-and-ssl-redirect\rls ingress/externaldns We will re-use the resources of previous section. Let copy all resources inside ingress/externaldns/host-header-routing-ingress to ingress/externaldns/ssl-and-ssl-redirect.  cp ingress/externaldns/host-header-routing-ingress/* ingress/externaldns/ssl-and-ssl-redirect\rls ingress/externaldns/ssl-and-ssl-redirect Open file 05-ALB-ingress.yaml, add the below annotations. Replace \u0026lt;REPLACE-WITH-YOUR-CERTIFICATE-ARN\u0026gt; with your created Certificate Arn and save it.  ## SSL Settings\ralb.ingress.kubernetes.io/listen-ports: \u0026#39;[{\u0026#34;HTTPS\u0026#34;:443}, {\u0026#34;HTTP\u0026#34;:80}]\u0026#39;\ralb.ingress.kubernetes.io/certificate-arn: \u0026lt;REPLACE-WITH-YOUR-CERTIFICATE-ARN\u0026gt; Deploy resources  Deploy resources on Namespace fcj-external-dns-ingress-ns.  kubectl apply -f ingress/externaldns/ssl-and-ssl-redirect -n fcj-external-dns-ingress-ns\rkubectl get all -n fcj-external-dns-ingress-ns Go to Load Balancer to verify the new created Application Load Balancer.  Click on it and verify that there is a new added Listener for HTTPS protocol on Port 443, and Default SSL/TLS certificate is the certificate which you created above.  Click on it to verify Listener rules.    With HTTPS traffic to port 443 with HTTP Host Header is firstcloudjourney-app1.\u0026lt;YOUR-DOMAIN-NAME\u0026gt;, it will be forwarded to Target Group of App1. With HTTPS traffic to port 443 with HTTP Host Header is firstcloudjourney-app2.\u0026lt;YOUR-DOMAIN-NAME\u0026gt;, it will be forwarded to Target Group of App2.  Verify the result.  Access to http://firstcloudjourney-app1.\u0026lt;YOUR-DNS-NAME\u0026gt;/app1.   We can connect to the application App1 but the connection is not secure.\nAccess to https://firstcloudjourney-app1.\u0026lt;YOUR-DNS-NAME\u0026gt;/app1.   With HTTPS protocol, the connection to application App1 is secure.\nSimilarly, access to http://firstcloudjourney-app2.\u0026lt;YOUR-DNS-NAME\u0026gt;/app2 and https://firstcloudjourney-app2.\u0026lt;YOUR-DNS-NAME\u0026gt;/app2 to verify the result.  Redirect HTTP traffic to HTTPS Port. Modify Manifest file.  Open file 05-ALB-ingress.yaml, add the below annotations. Then save it.  # SSL Redirect Setting\ralb.ingress.kubernetes.io/ssl-redirect: \u0026#39;443\u0026#39; Redeploy resources.  Redeploy resources on Namespace fcj-external-dns-ingress-ns.  kubectl apply -f ingress/externaldns/ssl-and-ssl-redirect -n fcj-external-dns-ingress-ns\rkubectl get all -n fcj-external-dns-ingress-ns Only the Ingress is configured. Access to your Application Load Balancer on Load Balancer again to see the changes.   The change appeared on HTTP:80, the Rules decreased from 3 to 1.\nClick on HTTP:80 to verify the change.   All Listener Rules were deleted, there is a new one created which will redirect to Port 443 when have traffic as default.\nVerify the result.  Access to http://firstcloudjourney-app1.\u0026lt;YOUR-DNS-NAME\u0026gt;/app1.   The traffic will be redirected to Port 443 with HTTPS protocol automatically.\nAccess to https://firstcloudjourney-app1.\u0026lt;YOUR-DNS-NAME\u0026gt;/app1.   The traffic to Port 443 with HTTPS protocol can still be accessed as normal.\nSimilarly, access to http://firstcloudjourney-app2.\u0026lt;YOUR-DNS-NAME\u0026gt;/app2 and https://firstcloudjourney-app2.\u0026lt;YOUR-DNS-NAME\u0026gt;/app2 to verify the result.   Clean up.  Delete the created resources.  kubectl delete -f ingress/externaldns/ssl-and-ssl-redirect -n fcj-external-dns-ingress-ns\rkubectl get all -n fcj-external-dns-ingress-ns We will retain resources which related to external-dns service and created SSL certificate on AWS Certificate Manager for next sections.\n"
},
{
	"uri": "/5-dnsingresswitheks/",
	"title": "(Optional) Integrate ExternalDNS Service for Amazon EKS Cluster",
	"tags": [],
	"description": "",
	"content": "Overview In this chapter, we will demonstrate how to integrate ExternalDNS Service (Route53 and AWS Certificate Manager) on Amazon EKS Cluster. This is an optional chapter, since it requests you need to have a associated Host Zone on Route53. If you do still not have it, you can purchase a domain name and add it on Host Zone or ony need to go through to get the overview of this concept.\nContent  5.1 Deploy ExternalDNS Service 5.2 Use ExternalDNS as Ingress Service 5.3 Name Based Virtual Host Routing 5.4 SSL and SSL Redirect 5.5 Target Type IP  "
},
{
	"uri": "/2-prerequiste/2.5-createapplication/",
	"title": "Create Application",
	"tags": [],
	"description": "",
	"content": "In this section, we will create a simple application with two versions V1 and V2. Then, dockerize and push them to DockerHub for EKS Cluster use.\nCreate application v1  At the Cloud9 terminal, enter the command below to create a new directory for application.  mkdir app\rcd app Initialize application.  npm init Press Enter to skip those step and confirm Yes to finish.  Create a file name index.js.  touch index.js Open index.js file and perform code.  import express from \u0026#39;express\u0026#39;  const app = express()  app.get(\u0026#39;/\u0026#39;,(req, res) =\u0026gt; {  res.json(\u0026#34;Hello world from FCJ Workshop V1!\u0026#34;) })  app.listen(8080, ()=\u0026gt; {  console.log(\u0026#34;application running on 8080\u0026#34;) }) At Cloud9 Terminal, let install express framework.  npm i express Save the file and enter this command in terminal to run the application.  node index.js  But you will get the error below.   To fix this error, open package.json file and add the definition below. Then save it.\n  \u0026#34;type\u0026#34;:\u0026#34;module\u0026#34;, Now, let enter the command to run your application again.  node index.js See, your application ran on port 8080.   Now, we need to access to application to see the result.\n Click on Share.\n  Copy the IP Address at Application field.   Access to the application with URL http://\u0026lt;REPLACE_YOUR_IP\u0026gt;:8080.\n  Opps, the application can not be accessed.   The reason is the security group of workspace instance is still not opened for port 8080.\n Click to R symbol and choose Manage EC2 Instance to go back to workspace instance.   At Instances page, select your workspace instance.\n  Navigate to Security tab.\n  Click to Security Group.   At Inbound rules interface, you can see there are no rules were defined.\nClick on Edit inbound rules.  At Edit inbound rules interface, click on Add rule.  Define the rule with parameter:   Type is Custom TCP. Port range is 8080. Source is Anywhere-IPv4.   Then, click on Save rules.   Now, let access to your application again and see the result.   Dockerize application v1  Create a file named Dockerfile.  touch Dockerfile  Open the Dockerfile.   Enter the code below.\n  FROMnode:13-alpine#configure working directoryWORKDIR/appCOPY package.json ./RUN npm install#bundle the source codeCOPY . ./EXPOSE8080CMD [\u0026#34;node\u0026#34;,\u0026#34;index.js\u0026#34;]Note:\n  At step COPY package.json ./, Docker will copy package.json file to working directory /app, then process step RUN npm install to install all dependencies were defined in package.json file and save them to node_modules folder.\n  At step COPY . ./, Docker will copy all resource to working directory /app - include node_modules folder and Dockerfile file. Those folders and files are not necessary to copy again to working directory. So you can create .dockerignore to list which file or folder do not need to copy to working directory.\n  Create file named .dockerignore by command.  touch .dockerignore You will not see where .dockerignore is, since Cloud9 recognize .dockerignore is hidden file.\nClick on Setting. Select Show Hidden Files.  Open .dockerignore and enter those values.  node_modules\rDockerfile Enter this command to list all container images in your machine.  docker images There is no existing image in workspace. 9. Let build container image.\ndocker build -t fcj-application:v1 . List existing images again.  docker images The container image of your application had been built with version v1 successfully.\nCreate application v2   Open index.js file and replace res.json(\u0026ldquo;Hello world from FCJ Workshop V1!\u0026rdquo;) to res.json(\u0026ldquo;Hello world from FCJ Workshop V2!\u0026rdquo;) at line 6.   Start your application to see the result   Access to your application URL again to verify the result.   Dockerize application v2  Let build container image.  docker build -t fcj-application:v2 . List existing images again.  docker images Push container image to DockerHub.   Access and sign in to DockerHub with your account.\n  Let create a repository for this workshop.   Input requested information:\n   Name: fcj-elbeks-workshop-basicapp. Description: Store container image for Amazon ELB with Amazon EKS Cluster Workshop. Then click on Create.   Next, we will create an access token used to log in DockerHub from workspace instance.\n Click on your avatar (on the page top right side).\n  Click on My Account.\n  Click on Security.\n  Finally, click on New Access Token.   Fill the Access Token Description.\n  Click on Generate.   Store generated access token to use later.   Back to terminal of Cloud9. Enter this command to login and provide password when be requested.\n  docker login -u \u0026lt;REPLACE-YOUR-DOCKERHUB-USERNAME\u0026gt; To push container image to repository, Repository of your container image must match with repository format of DockerHub \u0026lt;YOUR_USER_NAME\u0026gt;/\u0026lt;YOUR_REPOSITORY_NAME\u0026gt;. So now we need to use docker image tag command to copy and correct repository format of your container image in workspace instance.\nExecute this command to tag your container image version v1 and v2.  docker image tag fcj-application:v1 firstcloudjourneypcr/fcj-elbeks-workshop-basicapp:v1\rdocker image tag fcj-application:v2 firstcloudjourneypcr/fcj-elbeks-workshop-basicapp:v2 List all your container images again.  docker images Now, there are 2 new container images is firstcloudjourneypcr/fcj-elbeks-workshop-basicapp with tag is v1 and firstcloudjourneypcr/fcj-elbeks-workshop-basicapp with tag is v2. Next, let push those container images to DockerHub.\nExecute this command to push your container image both version v1 and v2 to DockerHub.  docker push firstcloudjourneypcr/fcj-elbeks-workshop-basicapp:v1\rdocker push firstcloudjourneypcr/fcj-elbeks-workshop-basicapp:v2 Back to your Docker Hub repository to check the result. There is 2 container images had been pushed to.  "
},
{
	"uri": "/5-dnsingresswitheks/5.5-targettypeip/",
	"title": "Target Type IP",
	"tags": [],
	"description": "",
	"content": "In this section, we will deploy application on Fargate Node with Ingress and ExternalDNS Service.\nCreate Manifest file.  Create new working directory for this section.  mkdir ingress/externaldns/target-type-ip\rls ingress/externaldns Create folder farget-profile to store fargate profile definition file.  mkdir ingress/externaldns/target-type-ip/farget-profile\rls ingress/externaldns/target-type-ip Create fargate-profile.yaml inside ingress/externaldns/target-type-ip/farget-profile.  touch ingress/externaldns/target-type-ip/farget-profile/fargate-profile.yaml\rls ingress/externaldns/target-type-ip/farget-profile/ Open file fargate-profile.yaml and paste the below code. Then save it.  apiVersion: eksctl.io/v1alpha5\rkind: ClusterConfig\rmetadata:\rname: fcj-elb-cluster\rregion: ap-southeast-1\rfargateProfiles:\r- name: fcj-fp\rselectors:\r- namespace: fcj-external-dns-ingress-ns\rlabels:\rrunon: fargate Create new folder to store manifest files to deploy application.  mkdir ingress/externaldns/target-type-ip/application\rls ingress/externaldns/target-type-ip Create a file named 01-App1-Deployment.yaml inside ingress/externaldns/target-type-ip/application.  touch ingress/externaldns/target-type-ip/application/01-App1-Deployment.yaml\rls ingress/externaldns/target-type-ip/application Open file 01-App1-Deployment.yaml and paste the below code. Then save it.  apiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: fcj-app1-deployment\rlabels:\rapp: fcj-app1\rrunon: fargate\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: fcj-app1\rtemplate:\rmetadata:\rlabels:\rapp: fcj-app1\rrunon: fargate spec:\rcontainers:\r- name: fcj-app1\rimage: stacksimplify/kube-nginxapp1:1.0.0\rports:\r- containerPort: 80 Create a file named 02-App1-ClusterIP.yaml inside ingress/externaldns/target-type-ip/application.  touch ingress/externaldns/target-type-ip/application/02-App1-ClusterIP.yaml\rls ingress/externaldns/target-type-ip/application Open file 02-App1-ClusterIP.yaml and paste the below code. Then save it.  apiVersion: v1\rkind: Service\rmetadata:\rname: fcj-app1-clusterip-service\rlabels:\rapp: fcj-app1\rrunon: fargate\rannotations:\ralb.ingress.kubernetes.io/healthcheck-path: /app1/index.html\rspec:\rtype: ClusterIP\rselector:\rapp: fcj-app1\rports:\r- port: 80\rtargetPort: 80 Similarly, create a file named 03-App2-Deployment.yaml and paste the below code. Then save it.  apiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: fcj-app2-deployment\rlabels:\rapp: fcj-app2\rrunon: fargate\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: fcj-app2\rtemplate:\rmetadata:\rlabels:\rapp: fcj-app2\rrunon: fargate\rspec:\rcontainers:\r- name: fcj-app2\rimage: stacksimplify/kube-nginxapp2:1.0.0\rports:\r- containerPort: 80 Similarly, create a file named 04-App2-ClusterIP.yaml and paste the below code. Then save it.  apiVersion: v1\rkind: Service\rmetadata:\rname: fcj-app2-clusterip-service\rlabels:\rapp: fcj-app2\rrunon: fargate\rannotations:\ralb.ingress.kubernetes.io/healthcheck-path: /app2/index.html\rspec:\rtype: ClusterIP\rselector:\rapp: fcj-app2\rports:\r- port: 80\rtargetPort: 80 Similarly, create a file named 05-ALB-ingress.yaml, paste the below code and replace \u0026lt;REPLACE-WITH-YOUR-HOST-HEADER-APP1\u0026gt; and \u0026lt;REPLACE-WITH-YOUR-HOST-HEADER-APP2\u0026gt; with your Host Header . Then save it.  apiVersion: networking.k8s.io/v1\rkind: Ingress\rmetadata:\rname: fcj-target-type-ip-ingress\rlabels:\rrunon: fargate\rannotations:\r# Load Balancer Name\ralb.ingress.kubernetes.io/load-balancer-name: fcj-target-type-ip\r# Ingress Core Settings\ralb.ingress.kubernetes.io/scheme: internet-facing\r# Health Check Settings\ralb.ingress.kubernetes.io/healthcheck-protocol: HTTP alb.ingress.kubernetes.io/healthcheck-port: traffic-port\ralb.ingress.kubernetes.io/healthcheck-interval-seconds: \u0026#39;15\u0026#39;\ralb.ingress.kubernetes.io/healthcheck-timeout-seconds: \u0026#39;5\u0026#39;\ralb.ingress.kubernetes.io/success-codes: \u0026#39;200\u0026#39;\ralb.ingress.kubernetes.io/healthy-threshold-count: \u0026#39;2\u0026#39;\ralb.ingress.kubernetes.io/unhealthy-threshold-count: \u0026#39;2\u0026#39;\r## SSL Settings\ralb.ingress.kubernetes.io/listen-ports: \u0026#39;[{\u0026#34;HTTPS\u0026#34;:443}, {\u0026#34;HTTP\u0026#34;:80}]\u0026#39;\ralb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:ap-southeast-1:170074558790:certificate/3798d174-1dc8-4380-974b-c219a4317730\r# SSL Redirect Setting\ralb.ingress.kubernetes.io/ssl-redirect: \u0026#39;443\u0026#39; # For Fargate\ralb.ingress.kubernetes.io/target-type: ip spec:\ringressClassName: my-aws-ingress-class # Ingress Class\rrules:\r- host: \u0026lt;REPLACE-WITH-YOUR-HOST-HEADER-APP1\u0026gt;\rhttp:\rpaths:\r- path: /\rpathType: Prefix\rbackend:\rservice:\rname: fcj-app1-clusterip-service\rport:\rnumber: 80\r- host: \u0026lt;REPLACE-WITH-YOUR-HOST-HEADER-APP2\u0026gt;\rhttp:\rpaths:\r- path: /\rpathType: Prefix\rbackend:\rservice:\rname: fcj-app2-clusterip-service\rport:\rnumber: 80 Deploy resources. Create Fargate Profile  Create Fargate Profile on your EKS Cluster.  eksctl create fargateprofile -f ingress/externaldns/target-type-ip/farget-profile/fargate-profile.yaml List Fargate Profile on EKS Cluster again.  eksctl get fargateprofile --cluster fcj-elb-cluster --region ap-southeast-1 Deploy resources.  Deploy resources on Namespace fcj-external-dns-ingress-ns.  kubectl apply -f ingress/externaldns/target-type-ip/application -n fcj-external-dns-ingress-ns List created resources.  kubectl get all -n fcj-external-dns-ingress-ns List all Nodes in your Cluster.  kubectl get node -o wide There are two create Fargate Instances for application App1 and App2.\nVerify the result.   Access to http://firstcloudjourney-app1.\u0026lt;YOUR-DNS-NAME\u0026gt;/app1.   Access to http://firstcloudjourney-app2.\u0026lt;YOUR-DNS-NAME\u0026gt;/app2.   Clean up  Delete the created resources.  kubectl delete -f ingress/externaldns/target-type-ip/application -n fcj-external-dns-ingress-ns\rkubectl get all -n fcj-external-dns-ingress-ns We will retain resources which related to external-dns service and created SSL certificate on AWS Certificate Manager for next sections.\nList current Node on your Cluster to verify two created Fargate Nodes deleted automatically.  kubectl get node -o wide "
},
{
	"uri": "/6-nlbwitheks/",
	"title": "Network Load Balancer service with Amazon EKS Cluster",
	"tags": [],
	"description": "",
	"content": "Overview In this chapter, we will demonstrate how to deploy application to Network Load Balancer and integrate ExternalDNS Service (Route53 and AWS Certificate Manager) on Amazon EKS Cluster.\nContent  6.1 Network Load Balancer service with Amazon EKS Cluster EC2 Managed Node 6.2 Network Load Balancer service with Amazon EKS Cluster Fargate Node  "
},
{
	"uri": "/7-cleanup/",
	"title": "Cleanup resources",
	"tags": [],
	"description": "",
	"content": "Delete Amazon EKS Cluster.  At Cloud9 terminal, execute the below command to delete your EKS Cluster.  eksctl delete cluster --name fcj-elb-cluster --region ap-southeast-1 It will take you about 15 minutes to delete successfully.  Delete AWS Certificate Manager certificate.   Go to AWS Certificate Manager certificate., select your created certificate.\n  Click on Delete.   Input delete to confirm.\n  Then, click on Delete to delete.   Delete created Route 53 Record.   Go to your Host Zone on Route 53.\n  Select the created Record by AWS Certificate Manager.\n  Click on Delete record.   Then, click on Delete to delete.\n  Delete Cloud9 Workspace.  Go to Cloud9. Select FCJ-Workspace. Click on Delete.  Input Delete to confirm. Click on Delete.   "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]