[
{
	"uri": "/vi/6-deploytoeks/6.1-installeks/",
	"title": "Cài đặt Amazon EKS",
	"tags": [],
	"description": "",
	"content": "eksctl là một câu lệnh đơn giản giúp ích cho việc tạo và quản lý Kubernetes clusters trên Amazon EKS.\n Tại cửa sổ lệnh Cloud9, thực thi câu lệnh dưới đây để cài đặt Amazon EKS.   Tải và trích xuất bản phát hành mới nhất của eksctl bằng lệnh sau.  curl --silent --location \u0026#34;https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz\u0026#34; | tar xz -C /tmp  Di chuyển nhị phân được trích xuất thành /usr/local/bin.  sudo mv /tmp/eksctl /usr/local/bin  Kiểm tra cài đặt.  eksctl version "
},
{
	"uri": "/vi/5-deploytok8s/5.1-installk8s/",
	"title": "Cài đặt công cụ Kubernetes",
	"tags": [],
	"description": "",
	"content": "Đầu tiên, chúng ta cần cài đặt Kubernetes (Minikube) lên máy chủ làm việc. Minikube mà một công cụ mà cho phép bạn chạy một Kubernetes cluster node đơn trong máy tính cá nhân hoặc máy chủ EC2 để bạn có thể thử nghiệm Kubernetes.\nMinikube là một bộ cài đặt Kubernetes (K8) gọn nhẹ, có thể tạo một Virtual Machine (VM) trên máy chủ nội bộ hoặc máy chủ đám mấy, triển khai một cluster đơn giản mà chỉ chứa 1 node.\nNhưng để cài đặt kubectl và minikube trong máy chủ làm việc, dung lượng lưu trữ phải dư thừa. Vì thế đầu tiên, chúng ta cần mở rộng dung lượng lưu trữ của máy chủ làm việc.\nMở rộng dung lượng lưu trữ lên 50GB.   Đi đến EC2 instance của máy chủ làm việc.   Chuyển đến mục Storage.\n  Nhấn Volume ID.   Dung lượng lưu trữ hiện tại là 10GB. Chúng ta sẽ nâng cấp nó lên 50GB. 4. Chọn EBS volume. 5. Nhấn Action. Sau đó chọn Modify volume. 6. Đổi từ 10 lên 50 tại mục Size (GiB). 7. Nhấn Modify.  Sau đó, nhấn Modify để xác nhận.   Trở lại Cloud9 terminal, thực thi câu lệnh dưới đây để khởi động lại máy chủ làm việc.\n  sudo reboot Sau khi khởi động thành công. Kiểm tra kết quả.  df -h Có một bộ lưu trữ được gắn thêm vào máy chủ của bạn với dung lượng là 43GB. Cài đặt kubectl  Tại Cloud9 Terminal, thực thi câu lệnh dưới đây để cài đặt kubectl.   Cập nhật máy chủ.  sudo yum update  Cài đặt kubectl.  curl -LO https://dl.k8s.io/release/v1.30.0/bin/linux/amd64/kubectl sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl Kiểm tra phiên bản kubectl.  kubectl version --client Cài đặt minikube  Tại Cloud9 Terminal, thực thi câu lệnh dưới đây để cài đặt minikube.  curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64\rsudo install minikube-linux-amd64 /usr/local/bin/minikube \u0026amp;\u0026amp; rm minikube-linux-amd64 Khởi chạy Kubernetes Cluster với minikube.  minikube start Kiểm tra phiên bản.  minikube version "
},
{
	"uri": "/vi/3-deployappwithdocker/3.1-installdocker/",
	"title": "Cài đặt Docker",
	"tags": [],
	"description": "",
	"content": "Ở bước này, chúng ta sẽ kiểm tra phiên bản của Docker và cài đặt nếu nó không tồn tại.\nKiểm tra phiên bản của Docker  Tại Cloud9 terminal, thực hiện dòng lệnh này để kiểm tra phiên bản của Docker.  docker version Bạn thấy, phiên bản Docker hiện là 25.0.3.\nChạy command này để kiểm tra Docker.  sudo docker run hello-world Cài đặt Docker nếu nó chưa tồn tại.  Cập nhật máy chủ của bạn.  sudo yum update -y Tải xuống gói Docker Community Edition.  sudo yum install -y docker 3. Khởi chạy dịch vụ Docker.\nsudo service docker start Thêm ec2-user vào Docker Group để có thể thực thi các câu lệnh với Docker mà không cần sử dụng sudo.  sudo usermod -a -G docker ec2-user Kiểm tra Docker.  sudo docker run hello-world "
},
{
	"uri": "/vi/1-introduce/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Docker Tổng quan Docker là một mã nguồn mở cho việc phát triển, di chuyển và triển khai ứng dụng. Docker cho phép bạn tách ứng dụng khỏi cơ sở hạ tầng để bạn có thể phân phối phần mềm nhanh chóng. Với Docker, bạn có thể quản lý hạ tầng như cách bạn quản lý ứng dụng. Bằng cách tận dụng các phương pháp của Docker để vận chuyển, kiểm thử và triển khai mã code, bạn có thể làm giảm đang kể độ trễ giữa việc viết mã code và triển khai nó trên môi trường sản phẩm.\nKiến trúc Docker The Docker daemon: Docker daemon lắng nghe các yêu cầu Docker API và quản lý các đối tượng Docker như image, container, network và volume. Một daemon cũng giao tiếp với các daemon khác để quản lý các dịch vụ Docker.\nThe Docker client: Docker client là cách chính để nhiều người dùng Docker tương tác với Docker. Khi bạn sử dụng dòng lệnh, client gửi những dòng lệnh đó đến Docker daemon để thực hiện chúng. Dòng lệnh Docker sử dụng Docker API. Docker client có thể giao tiếp với một hoặc nhiều Docker daemon.\nDocker Desktop: Docker Desktop là một ứng dụng dễ dàng cài đặt cho môi trường Mac, Windows hoặc Linux that enables you to build and share containerized applications and microservices. mà cho phép bạn xây dựng và chia sẻ các ứng dụng và microservice được đóng gói trong container.\nDocker registries: Docker registry chứa Docker images. Docker Hub là một công cộng mà mọi người có thể dùng, và Docker mặc định tìm kiếm images trên Docker Hub.\nImages: Một image là một bản mẫu chỉ đọc với các hướng dẫn cho việc tạo một Docker container.\nContainers: Container là một phiên bản có thể triển khai của image. Bạn có thể tạo, khởi chạy, dừng, di chuyển hoặc xóa một container bằng cách sử dụng Docker API hoặc CLI.\nTruy cập Docker docs để thêm thông tin.\n\rKubernetes Tổng quan Kubernetes là một nền tảng nguồn mở, có thể mở rộng, di động để quản lý khối lượng công việc và dịch vụ được đóng gói, tạo điều kiện thuận lợi cho cả cấu hình khai báo và tự động hóa. Nó có một hệ sinh thái rộng lớn và phát triển nhanh chóng. Các dịch vụ, hỗ trợ và công cụ của Kubernetes có sẵn rộng rãi.\nKiến trúc cụm Kubernetes Cluster: Kubernetes Cluster bao gồm một tập hợp các worker node, được gọi là node, chạy các ứng dụng được đóng gói. Mỗi cụm có ít nhất một worker node.\nControl Plane: Control Plane quản lý các worker node và Pod trong Cluster. Trong môi trường sản phẩm, Control Plane thường hoạt động trên nhiều máy chủ và một cluster thường có nhiều node để đảm bảo tính sẵn sàng và khả nằng chịu lỗi cao.\nWorker Nodes: Work Node chứa các Pods là các thành phần của khối lượng công việc ứng dụng.\nkube-api-server: The API server là một thành phần của Kubernetes control plane mà hiển thị Kubernetes API. Máy chủ API là giao diện cho Kubernetes control plane.\netcd: Bộ lưu trữ key-value nhất quán và khả dụng cao được sử dụng như kho lưu trữ hổ trợ Kubernetes cho tất cả dữ liệu của Cluster. Scheduler: Là thành phần của Control plane giám sát các Pod mới tạo chưa được chỉ định nào node nào, và sẽ chọn một node phù hợp để chúng triển khai trên.\nController Manager: Là thành phần của Control plane chạy các quy trình quản lý. Một cách hợp lý, mỗi bộ điều khiển sẽ là một quy trình riêng biệt nhưng để giảm sự phức tạp, chúng thường được biên dịch thành một tện nhị phân duy nhất để chạy trên một quy trình duy nhất. Có nhiều loại bộ điều khiển khác nhau. Một số ví dụ như:\n Node controller: Chịu trách nhiệm nhận diện và phản hổi khi node không hoạt động. Job controller: Theo dõi các đối tượng Công việc đại diện cho các nhiệm vụ một lần, sau đó tạo các Pod để chạy các nhiệm vụ đó cho đến khi hoàn thành EndpointSlice controller: Điền vào các đối tượng EndpointSlice (để cung cấp liên kết giữa Service và Pod) ServiceAccount controller: Tạo ServiceAccounts mặc định cho một namespace mới.  Trên đây không phải là danh sách đầy đủ.\nkubelet: Một agent chạy trên mỗi node trong cluster. It makes sure that containers are running in a Pod. Nó đảm bảo rằng các container đang chạy trong Pod.\nkube-proxy: kube-proxy là một proxy mạng chạy trên mỗi node trong cluster của bạn, triển khai một phần khái niệm Service Kubernetes.\npod: là một phiên bản duy nhất của một ứng dụng và đối tượng nhỏ nhất mà bạn có thể tạo trong Kubernetes.\nContainer Runtime Interface (CRI): Một thành phần cơ bản hỗ trợ Kubernetes chạy các container một cách hiệu quả. Nó chịu trách nhiệm quản lý việc thực thi và vòng đời của các container trong môi trường Kubernetes.\ncloud-control-manager: Một thành phần Kubernetes control plane nhúng bộ điều khiển dành riêng cho đám mây. Trình quản lý bộ điều khiển đám mây cho phép bạn liên kết cụm của mình với API của nhà cung cấp đám mây và tách các thành phần tương tác với nền tảng đám mây đó khỏi các thành phần chỉ tương tác với cụm của bạn.\nTruy cập Kubernetes docs để thêm thông tin.\n\rAmazon EKS Tổng quan Amazon Elastic Kubernetes Service (Amazon EKS) là một dịch vụ được quản lý giúp loại bỏ sự cần thiết của việc cài đặt, vận hành và duy trì Kubernetes control plane của bạn trên Amazon Web Services (AWS).\nKiến trúc Amazon EKS Amazon EKS đảm bảo mỗi cluster đều có Kubernetes control plane riêng biệt. Thiết kế này giữ cho cơ sở hạ tầng của mỗi cụm tách biệt, không trùng lập giữa các Cluster hoặc tài khoản AWS. Việc thiết lập bao gồm:\n Các thành phần phân tán: Control plane chứa ít nhất 2 phiên bản máy chủ API (API server) và 3 phiên bản etcd giữa 3 AWS Availability Zone trong một AWS Region. Tối ưu hiệu suất: Amazon EKS giám sát chủ động và điều chỉnh các phiên bản Control plane để duy trì hiệu năng cao nhất. Khả năng phục hồi: Nếu một phiên bản Control plane không hoạt động, Amazon EKS nhanh chóng thay thế nó, sử dụng Availability Zone khác nếu cần thiết. Thời gian hoạt động ổn định: Bằng việc triển khai các Cluster giữa các Availability Zone, đạt được tính khả dụng của điểm cuối máy chủ API (SLA) đáng tin cậy.  Amazon EKS sử dụng Amazon Virtual Private Cloud (Amazon VPC) để giới hạn lưu lượng giữa các thành phần Control plane bên trong một Cluster. Các thành phần Cluster không thể nhìn thấy hoặc nhận giap tiếp từ các Cluster hoặc tài khoản AWS khác, ngoại trừ khi được xác thực bởi quy tắc Kubernetes role-based access control (RBAC).\nNgoài Control plane, một Amazon EKS cluster còn có một tập các worker machines gọi là node. Việc lựa chọn lại Amazon EKS cluster node thích hợp là rất quan trọng để đáp ứng các yêu cầu cụ thể của bạn và tối ưu hóa việc sử dụng tài nguyên. Amazon EKS cung cấp các loại node chính sau:\n AWS Fargate: Fargate là công cụ điện toán serverless dành cho vùng chứa giúp loại bỏ nhu cầu quản lý các phiên bản cơ bản. Với Fargate, bạn chỉ định nhu cầu tài nguyên của ứng dụng và AWS sẽ tự động cung cấp, thay đổi quy mô và duy trì cơ sở hạ tầng. Tùy chọn này lý tưởng cho những người dùng ưu tiên tính dễ sử dụng và muốn tập trung vào phát triển và triển khai ứng dụng thay vì quản lý cơ sở hạ tầng. Karpenter: Karpenter là một công cụ tự động chia tỷ lệ Kubernetes Cluster linh hoạt, hiệu suất cao, giúp cải thiện tính khả dụng của ứng dụng và hiệu quả của cụm. Karpenter khởi chạy các tài nguyên điện toán có kích thước phù hợp để đáp ứng nhu cầu tải ứng dụng thay đổi. Tùy chọn này có thể cung cấp tài nguyên điện toán kịp thời đáp ứng yêu cầu khối lượng công việc của bạn. Managed node groups: Managed node groups là sự kết hợp giữa tự động hóa và tùy chỉnh để quản lý tập hợp phiên bản Amazon EC2 trong Amazon EKS cluster. AWS đảm nhiệm các nhiệm vụ như vá lỗi, cập nhật và thay đổi quy mô node, giúp đơn giản hóa các khía cạnh vận hành. Song song đó, các đối số kubelet tùy chỉnh được hỗ trợ, mở ra khả năng cho các chính sách quản lý bộ nhớ và CPU nâng cao. ơn nữa, chúng còn tăng cường bảo mật thông qua vai trò AWS Identity and Access Management (IAM) cho các tài khoản dịch vụ, đồng thời hạn chế nhu cầu về các quyền riêng biệt cho mỗi cluster. Self-managed nodes: Self-managed nodes cung cấp toàn quyền kiểm soát các phiên bản Amazon EC2 của bạn trong Amazon EKS cluster. Bạn chịu trách nhiệm quản lý, mở rộng quy mô và duy trì các node, mang lại cho bạn toàn quyền kiểm soát cơ sở hạ tầng cơ bản. Tùy chọn này phù hợp với những người dùng cần kiểm soát và tùy chỉnh chi tiết các node của họ và sẵn sàng đầu tư thời gian vào việc quản lý và duy trì cơ sở hạ tầng của họ.   Truy cập Amazon EKS docs để thêm thông tin.\n\r"
},
{
	"uri": "/vi/",
	"title": "Triển khai ứng dụng đầu tiên trên Amazon EKS",
	"tags": [],
	"description": "",
	"content": "Triển khai ứng dụng đầu tiên trên Amazon EKS Tổng quan Trong bài thực hành này, chúng ta sẽ cùng tìm hiểu các khái niệm cơ bản và cách thức triển khai một ứng dụng đơn giản trên Docker, Kubernetes và Amazon EKS.\nNội dung  Giới thiệu Các bước chuẩn bị  2.1 Tạo môi trường Cloud9 2.2 Cấu hình IAM Role 2.3 Cài đặt ứng dụng 2.4 Tạo ứng dụng cơ bản   Triển khai ứng dụng với Docker  3.1 Cài đặt Docker 3.2 Tạo Dockerfile cho ứng dụng 3.3 Tạo container image cho ứng dụng 3.4 Triển khai ứng dụng với Docker   Thao tác với Public Container Registry  4.1 Tạo tài khoản DockerHub 4.2 Đẩy container image lên DockerHub 4.3 Tải container image từ Docker   Triển khai ứng dụng với Kubernetes  5.1 Cài đặt Kubernetes 5.2 Triển khai ứng dụng với Kubernetes POD bằng kubectl 5.3 Triển khai ứng dụng với kubernetes POD bằng YAML manifest file   Triển khai ứng dụng với EKS  6.1 Cài đặt eksclt 6.2 Triển khai ứng dụng bằng EKS Cluster Managed nodegroup   Dọn dẹp tài nguyên  "
},
{
	"uri": "/vi/2-prerequiste/2.1-createcloud9workspace/",
	"title": "Tạo môi trường làm việc Cloud9",
	"tags": [],
	"description": "",
	"content": "Tạo môi trường làm việc Cloud9   Đi đến Cloud9 tại vùng ap-southeast-1.\n  Nhấn Create environment.   Tại trang Create environment, nhập FCJ-Workspace tại Name.\n  Nhập Workspace for hands on workshop tại Description.\n  Ở mục Environment type, giữ mặc định New EC2 instance.\n  Ở mục Instance type, chọn Additional instance types.\n  Ở mục Additional instance types, chọn t3.large.   Cuộn xuống cuối trang và nhấn Create.   Máy chủ làm việc đang được tạo.   Mất khoảng 2 phút để máy chủ tạo thành công.\n  Sau khi máy chủ tạo thành công, nhấn Open để bắt đầu.   "
},
{
	"uri": "/vi/4-interactpcr/4.1-createdockerhubacc/",
	"title": "Tạo tài khoản DockerHub",
	"tags": [],
	"description": "",
	"content": " Truy cập DockerHub. Nhấn Sign up để đăng ký tài khoản. Sau đó đăng nhập tài khoản của bạn.  Sau khi đăng nhập, bạn sẽ được yêu cầu điền Username. Đây là giá trị duy nhất. Sau đó, nhấn Sign Up.   Tại mục Repository, nhấn Create repository để lưu trữ container image.   Điền Repository Name với giá trị mybasicapp.\n  Sau đó nhấn Create.\n  Kế tiếp, chúng ta sẽ tạo Access Token được sử dụng để đăng nhập vào DockerHub từ máy chủ làm việc.\n Nhấn vào tài khoản của bạn (Phía trên bên phải của trang).\n  Nhấn My Account.\n  Nhấn Security.\n  Cuối cùng, nhấn New Access Token.   Điền Access Token Description.\n  Nhấn Generate.   Lưu lại mã token.\n  Trở lại terminal của Cloud9. Nhập command này để đăng nhập và cung cấp access token khi được yêu cầu.  docker login -u \u0026lt;REPLACE-YOUR-DOCKERHUB-USERNAME\u0026gt; "
},
{
	"uri": "/vi/2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "Tổng quan Để tiên hành bài lab này, chúng ta phải chuẩn bị một máy chủ làm việc Cloud9 và tạo IAM Role cho máy chủ đó.\nNội dung  2.1 Tạo môi trường Cloud9 2.2 Cấu hình IAM Role 2.3 Cài đặt ứng dụng 2.4 Tạo ứng dụng cơ bản  "
},
{
	"uri": "/vi/2-prerequiste/2.2-modifyiamrole/",
	"title": "Cấu hình IAM role",
	"tags": [],
	"description": "",
	"content": "Trong bước này, chúng ta sẽ tạo một IAM Role và gán nó cho máy chủ làm việc.\nTạo IAM role   Nhấn IAM để chuyển hướpg đến dịch vụ IAM.\n  Nhấn Role.\n  Nhấn Create role.   Ở mục Trusted entity type, chọn AWS service.\n  Ở mục Service or use case, chọn EC2.   Sau đó, nhấn Next.   Ở mục Permissions policies, chọn policy tên AdministratorAccess.   Sau đó, nhấn Next.   Tại trang Name, review, and create, nhập eksworkspace-administrator ở mục Role name .   Sau đó, cuộn xuống cuối trang và nhấn Create role.   Gán role cho máy chủ làm việc   Tại trang AWS Cloud9, nhấn Manage EC2 instance.   Bạn sẽ thấy máy chủ làm việc đã được tạo. Sau đó, nhấn chọn nó.\n  Nhấn Action.\n  Nhấn Security.\n  Nhấn Modify IAM role.   Chọn Role eksworkspace-administrator vừa được tạo ở bước trên.\n  Sau đó, nhấn Update IAM role.   IAM Role mới đã được cập nhật thành công.   Cập nhật cấu hình Cloud9 Cloud9 sẽ quản lý thông tin xác thực IAM tự dộng. Cấu hình mặc định này hiện không phù hợp với xác thực EKS thông qua IAM, chúng ta sẽ cần phải vô hiệu hóa tính năng này và sử dụng IAM Role.\n\r  Tại trang AWS Cloud9, nhấn AWS Cloud9.\n  Chọn Preferences.   Tại mục AWS Settings, vô hiệu hóa AWS managed temporary credentials.   Để đảm bảo rằng các thông tin xác thực tạm thời không còn lưu trữ trong Cloud9, chúng ta sẽ xóa tất cả thông tin xác thực đang tồn tại với dòng lệnh bên dưới.\n  rm -vf ${HOME}/.aws/credentials "
},
{
	"uri": "/vi/6-deploytoeks/6.2-eksmanagednodegroup/",
	"title": "Triển khai ứng dụng lên EKS Cluster Managed Nodegroup",
	"tags": [],
	"description": "",
	"content": "Một Kubernetes node mà một máy chạy các ứng dụng được đóng gói theo phương thức container. Mỗi node có các thành phần sau:\n Container runtime – Phần mềm có trách nhiệm cho việc khởi chạy container. kubelet – Đảm bảo rằng các container hoạt động tốt và chạy trong Pod được liên kết của chúng. kube-proxy – Duy trì các quy tắc mạng cho phép liên lạc với Pod của bạn  Amazon EKS cung cấp các loại node chính sau:\n AWS Fargate: Fargate là công cụ điện toán serverless dành cho vùng chứa giúp loại bỏ nhu cầu quản lý các phiên bản cơ bản. Với Fargate, bạn chỉ định nhu cầu tài nguyên của ứng dụng và AWS sẽ tự động cung cấp, thay đổi quy mô và duy trì cơ sở hạ tầng. Tùy chọn này lý tưởng cho những người dùng ưu tiên tính dễ sử dụng và muốn tập trung vào phát triển và triển khai ứng dụng thay vì quản lý cơ sở hạ tầng. Karpenter: Karpenter là một công cụ tự động chia tỷ lệ Kubernetes Cluster linh hoạt, hiệu suất cao, giúp cải thiện tính khả dụng của ứng dụng và hiệu quả của cụm. Karpenter khởi chạy các tài nguyên điện toán có kích thước phù hợp để đáp ứng nhu cầu tải ứng dụng thay đổi. Tùy chọn này có thể cung cấp tài nguyên điện toán kịp thời đáp ứng yêu cầu khối lượng công việc của bạn. Managed node groups: Managed node groups là sự kết hợp giữa tự động hóa và tùy chỉnh để quản lý tập hợp phiên bản Amazon EC2 trong Amazon EKS cluster. AWS đảm nhiệm các nhiệm vụ như vá lỗi, cập nhật và thay đổi quy mô node, giúp đơn giản hóa các khía cạnh vận hành. Song song đó, các đối số kubelet tùy chỉnh được hỗ trợ, mở ra khả năng cho các chính sách quản lý bộ nhớ và CPU nâng cao. ơn nữa, chúng còn tăng cường bảo mật thông qua vai trò AWS Identity and Access Management (IAM) cho các tài khoản dịch vụ, đồng thời hạn chế nhu cầu về các quyền riêng biệt cho mỗi cluster. Self-managed nodes: Self-managed nodes cung cấp toàn quyền kiểm soát các phiên bản Amazon EC2 của bạn trong Amazon EKS cluster. Bạn chịu trách nhiệm quản lý, mở rộng quy mô và duy trì các node, mang lại cho bạn toàn quyền kiểm soát cơ sở hạ tầng cơ bản. Tùy chọn này phù hợp với những người dùng cần kiểm soát và tùy chỉnh chi tiết các node của họ và sẵn sàng đầu tư thời gian vào việc quản lý và duy trì cơ sở hạ tầng của họ.  Nhưng trong bài thực hành này, chúng ta sẽ chỉ tập trung vào việc triển khai ứng dụng trên Amazon EKS Cluster Managed Nodegroup.\nTạo EKS Cluster  Tại cửa sổ lệnh Cloud9, thực thi câu lệnh dưới để tạo EKS Cluster.  eksctl create cluster --name=my-fcj-cluster --region=ap-southeast-1 --zones=ap-southeast-1a,ap-southeast-1b --managed --nodegroup-name=my-fcj-node --nodes=2 --node-type=t3.micro Sẽ mất khoảng 20 phút để hoàn tất.\n\r2. Sau khi quá trình tạo Cluster hoàn tất, liệt kê cluster của bạn trong máy chủ làm việc.\neksctl get cluster Liệt kê Nodes trong Cluster.  kubectl get node Có 2 node được liệt kê trong EKS Cluster.\nDi chuyển đến EC2 Instance để thấy các máy chủ kết nối với Node Group.   Có 2 máy chủ được tạo (khớp với \u0026ndash;nodes=2 trong câu lệnh eksctl) với tên là my-fcj-cluster-my-fcj-node-Node (định dạng --Node), loại t3.micro (khớp với \u0026ndash;node-type=t3.micro trong câu lệnh eksctl) và Availability Zone là ap-southeast-1a và ap-southeast-1b (khớp với \u0026ndash;zones=ap-southeast-1a,ap-southeast-1b trong câu lệnh eksctl).\nKhám phá EKS Cluster   Đi đến CloudFormation, chúng ta sẽ thấy có 2 stack được tạo - 1 cho việc tạo EKS Cluster và 1 cho EKS NodeGroup.   Đi đến Amazon EKS, chúng ta sẽ thấy có 1 EKS Cluster tên my-fcj-cluster. Nhấn vào nó.   Chuyển đến mục Compute.\n  Chúng ta sẽ thấy node group tên my-fcj-node với Desired size là 2 liên kết với EKS Cluster tại mục Node groups.   Triển khai ứng dụng lên EKS Cluster  Tại thư mục kube-manifest, thực thi câu lệnh sau để triển khai ứng dụng lên EKS Cluster.  kubectl apply -f . Liệt kê các Service được tạo ra.  kubectl get svc hoặc\nkubectl get service Truy cập LoadBalancer HostName để kiểm tra kết quả. Thay thế EXTERNAL-IP dịch vụ của bạn trong http://\u0026lt;REPLACE-YOUR-EXTERNAL-IP\u0026gt;:8080.  Example: Trường hợp này Hostname sẽ là http://a6d733c6da3c1499f9ac945a665aa815-1253515241.ap-southeast-1.elb.amazonaws.com:8080 Chúc mừng, bạn đã triển khai ứng dụng lên EKS CLuster Managed Node Group thành công. Dọn dẹp.  Tại cửa sổ lệnh Cloud9, để xóa hết tất cả tài nguyên đã tạo. Thực thi câu lệnh bên dưới.  kubectl delete -f . Liệt kê tất cả tài nguyên để đảm bảo chúng đã bị xóa hoàn toàn.  kubectl get all "
},
{
	"uri": "/vi/5-deploytok8s/5.2-deployk8simperative/",
	"title": "Triển khai ứng dụng với Kubernetes POD bằng kubectl",
	"tags": [],
	"description": "",
	"content": "Ở bước trước đó, chúng ta đã cài đặt kubectl và minikube thành công. Tại bước này, chúng ta sẽ triển khai ứng dụng trên Kubernetes Deployment bằng mệnh lệnh (Imperative).\n Liệt kê tất cả image trong máy chủ làm việc.  docker images Thực thi câu lệnh dưới đây để tạo Kubernetes Deployment trong Minikube Cluster với container image của ứng dụng của bạn.  kubectl create deployment mybasicapp --image=firstcloudjourneypcr/mybasicapp:v1 Liệt kê và kiểm tra Deployment tên mybasicapp.  kubectl get deployment Liệt kê POD được tạo bởi Deployment mybasicapp.  kubectl get pod Bây giờ, POD của ứng dụng đã được tạo nhưng không thể truy cập. Để truy cập POD, chúng ta cần tạo Service.\nThực thi câu lệnh này để tạo Service Load Balancer.  kubectl expose deployment mybasicapp --type=LoadBalancer --port=8080 Liệt kê và kiểm tra Service tên mybasicapp.  kubectl get service Tạo một đường dẫn để truy cập Load Balancer.  minikube tunnel  NhấnWindow. Chọn New Terminal để tạo một cửa sổ lệnh riêng biệt.   Liệt kê cà kiểm tra Service tên mybasicapp lần nữa.\n  kubectl get service EXTERNAL-IP xuất hiện.\nBây giờ chứng ta kiểm thử ứng dụng bằng câu lệnh.  curl http://\u0026lt;REPLACE-WITH-EXTERNAL-IP\u0026gt;:8080 Chúc mừng, ứng dụng của bạn đã được triển khai lên Minikube sử dụng kubectl thành công. Xóa Deployment và Service của ứng dụng.  kubectl delete deployment mybasicapp\rkubectl delete service mybasicapp Kiểm tra Deployment và Service lần nữa để đảm bảo chúng đã được xóa.  kubectl get all "
},
{
	"uri": "/vi/5-deploytok8s/5.3-deployk8sdeclarative/",
	"title": "Triển khai ứng dụng với Kubernetes POD bằng YAML manifest",
	"tags": [],
	"description": "",
	"content": "Ở bước trước đó, chúng ta sẽ triển khai ứng dụng trên Kubernetes Deployment bằng mệnh lệnh (Imperative). Ở bước này, chúng ta sẽ tìm hiểu cách triển khai ứng dụng trên Kubernetes Deployment bằng tệp manifest YAML (Declarative)\n Tạo một thư mục tên kube-manifest.  mkdir kube-manifest\rcd kube-manifest Tạo một tệp tên 01.mybasicapp-deployment.yaml.  touch 01.mybasicapp-deployment.yaml Mở tệp 01.mybasicapp-deployment.yaml. Dán đoạn mã code dưới đây và lưu lại.  apiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: mybasicapp-deployment\rlabels:\rapp: mybasicapp\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: mybasicapp\rtemplate:\rmetadata:\rlabels:\rapp: mybasicapp\rspec:\rcontainers:\r- name: mybasicapp\rimage: firstcloudjourneypcr/mybasicapp:v1\rports: - containerPort: 8080 Tạo một tệp tên 02.mybasicapp-service.yaml và lưu đoạn mã code dưới đây.  apiVersion: v1\rkind: Service\rmetadata:\rname: mybasicapp-service\rlabels:\rapp: mybasicapp\rspec:\rselector:\rapp: mybasicapp\rtype: LoadBalancer\rports:\r- port: 8080\rtargetPort: 8080 Áp dụng các tệp Kubernetes.  kubectl apply -f . Sau đó, kiểm tra Deployment, Service và POD vừa được tạo.  kubectl get all Kiểm tra ứng dụng.  curl http://\u0026lt;REPLACE-WITH-EXTERNAL-IP\u0026gt;:8080 Chúc mừng, ứng dụng của bạn đã được triển khai trên Minikube sử dụng tệp manifest thành công. Để xóa Deployment và Service được tạo ra bằng phương thức khai báo, sử dụng câu lệnh này.  kubectl delete -f . Kiểm tra Deployment và Service lần nữa để đảm bảo rằng chúng đã được xóa.  kubectl get all Stop your Minikube Cluster to save the resource.  minikube stop "
},
{
	"uri": "/vi/3-deployappwithdocker/3.2-createdockerfile/",
	"title": "Tạo Dockerfile",
	"tags": [],
	"description": "",
	"content": "Ở bước này, chúng ta sẽ tạo Dockerfile để hướng dẫn Docker làm thể nào để xây dựng container image cho ứng dụng.\n Tạo tệp tên Dockerfile.  touch Dockerfile  Mở tệp Dockerfile.   Nhập đoạn code bên dưới.\n  FROMnode:13-alpine#configure working directoryWORKDIR/appCOPY package.json ./RUN npm install#bundle the source codeCOPY . ./EXPOSE8080CMD [\u0026#34;node\u0026#34;,\u0026#34;index.js\u0026#34;]Chú ý:\n  Tại bước COPY package.json ./, Docker sẽ sao chép tệp package.json tới vùng làm việc /app, sau đó thực thi bước RUN npm install để cài đặt tất cả các gói tin được định nghĩa trong tệp package.json và lưu chúng vào thư mục node_modules.\n  Tại bước COPY . ./, Docker sao chép tất cả các tài nguyên đến vùng làm việc /app - bao gồm thư mục node_modules và tệp Dockerfile. Các thư mục và tệp này không cần thiết phải sao chép lại lên vùng làm việc. Vì thế bạn có thể tạo một tệp .dockerignore để liệt kê các tệp hoặc thư mục không cần thiết được sao chép lên vùng làm việc.\n  Tạo tệp tên .dockerignore.  touch .dockerignore Bạn sẽ không thấy .dockerignore ở đâu, vì Cloud9 nhận định .dockerignore là tệp ẩn.\nNhấn Setting. Chọn Show Hidden Files.  Mở .dockerignore và nhập các giá trị.  node_modules\rDockerfile "
},
{
	"uri": "/vi/4-interactpcr/4.2-pushimagetodockerhub/",
	"title": "Đẩy image lên DockerHub",
	"tags": [],
	"description": "",
	"content": "Ở bước trước, chúng ta đã tạo tài khoản DockerHub, kho lưu trữ công cộng và đăng nhập thành công. Bây giờ, chúng ta sẽ thực hiện đẩy container image lên nơi lưu trữ.\n Hãy liệt kê container images trong máy chủ làm việc.  docker images Như bạn có thể thấy, chúng ta chỉ có duy nhất Repository là fcj-application. Để đẩy container image lên repository, Repository của container image phải khớp với mẫu repository của DockerHub \u0026lt;YOUR_USER_NAME\u0026gt;/\u0026lt;YOUR_REPOSITORY_NAME\u0026gt;. Vì thế chúng ta cần sử dụng câu lệnh docker image tag để sao chép và chuẩn hóa mẫu repository của container image trong máy chủ làm việc.\nThực thi câu lệnh này để gắn nhãn cho container image.  docker image tag fcj-application:v1 firstcloudjourneypcr/mybasicapp:v1 Sau đó, hãy liệt kê các container image trong máy chủ làm việc một lần nữa để kiểm tra kết quả.  docker images Bây giờ, có 2 container image. Cái mới tạo có repository tên firstcloudjourneypcr/mybasicapp với nhãn v1. Kế tiếp, hãy đẩy container image này lên DockerHub.\nThực thi câu lệnh để đẩy container image lên DockerHub.  docker push firstcloudjourneypcr/mybasicapp:v1 Trở về Docker Hub repository để kiểm tra kết quả. Có 1 image container đã được đẩy lên.  "
},
{
	"uri": "/vi/2-prerequiste/2.3-installation/",
	"title": "Cài đặt ứng dụng",
	"tags": [],
	"description": "",
	"content": "Trong bài thực hành này, chúng ta sẽ tạo một ứng dụng đơn giản với NodoJS và Express. Vì thế chúng ta cần kiểm tra phiên bản của chúng và tải xuống nếu chúng chưa được cài đặt.\nNâng cấp awscli  Sao chép và dán dòng lệnh dưới đây vào Terminal của Cloud9 Workspace để nâng cấp awscli.  sudo pip install --upgrade awscli \u0026amp;\u0026amp; hash -r Kiểm tra phiên bản của npm và node  Sao chép và dán dòng lệnh dưới đây vào Terminal của Cloud9 Workspace để kiểm tra phiên bản của npm và node.  npm version Bạn có thể thấy, npm và node đã được cài đặt. Giờ chúng ta sẽ cài đặt Express framework bằng npm.\nCài đặt Express framework  Sao chép và dán dòng lệnh dưới đây vào Terminal của Cloud9 Workspace để cài đặt Express framework.  npm install express --save "
},
{
	"uri": "/vi/4-interactpcr/4.3-pullimagefromdockerhub/",
	"title": "Kéo image về từ DockerHub",
	"tags": [],
	"description": "",
	"content": "Ở bước trước đó, chúng ta đã đẩy container image lên DockerHub repository. Tại bước này, chúng ta sẽ kéo container image về máy chủ làm việc từ DockerHub repository. Để làm điều đó, trước tiên chúng ta cần xóa tất cả image trong máy chủ làm việc. Sau đó thực hiện việc kéo container image về và chạy ứng dụng từ image đó.\n Hãy liệt kê tất cả các image trông máy chủ làm việc.  docker images Có 2 container image trong máy chủ làm việc. 2. Kế tiếp, thực thi câu lệnh dưới để xóa chúng. Xác nhận Y khi được yêu cầu.\ndocker image prune -a Liệt kê image một lần nữa để đảm bảo tất cả đã được xóa.  docker images Bây giờ chúng ta sẽ kéo container image về từ DockerHub repository bằng câu lệnh.  docker pull firstcloudjourneypcr/mybasicapp:v1 Sau đó, liệt kê các image đã kéo về  docker images Chúng ta thấy có 1 image vừa được kéo về thành công.\nBây giờ, chúng ta sẽ triển khai image này lên Docker để khởi chạy ứng dụng cho mục đích kiểm thử.  docker run --name demoapplication -d -p 8080:8080 firstcloudjourneypcr/mybasicapp:v1 Kiểm tra process đang chạy trong máy chủ làm việc.  docker ps Ứng dụng đã được triển khai thành công.\nTruy cập ứng dụng để kiểm tra kết quả.   Chúc mừng, bạn đã kéo container image về từ Public Container Registry - DockerHub và triển khai nó lên Docker thành công! "
},
{
	"uri": "/vi/3-deployappwithdocker/",
	"title": "Triển khai ứng dụng với Docker",
	"tags": [],
	"description": "",
	"content": "Trong phần này, chúng ta sẽ triển khai ứng dụng sử dụng Docker để hiểu được cách thức đóng gói và triển khai một ứng dụng.\nTổng quan Docker là một mã nguồn mở cho việc phát triển, di chuyển và triển khai ứng dụng. Docker cho phép bạn tách ứng dụng khỏi cơ sở hạ tầng để bạn có thể phân phối phần mềm nhanh chóng. Với Docker, bạn có thể quản lý hạ tầng như cách bạn quản lý ứng dụng. Bằng cách tận dụng các phương pháp của Docker để vận chuyển, kiểm thử và triển khai mã code, bạn có thể làm giảm đang kể độ trễ giữa việc viết mã code và triển khai nó trên môi trường sản phẩm.\nKiến trúc Docker The Docker daemon: Docker daemon lắng nghe các yêu cầu Docker API và quản lý các đối tượng Docker như image, container, network và volume. Một daemon cũng giao tiếp với các daemon khác để quản lý các dịch vụ Docker.\nThe Docker client: Docker client là cách chính để nhiều người dùng Docker tương tác với Docker. Khi bạn sử dụng dòng lệnh, client gửi những dòng lệnh đó đến Docker daemon để thực hiện chúng. Dòng lệnh Docker sử dụng Docker API. Docker client có thể giao tiếp với một hoặc nhiều Docker daemon.\nDocker Desktop: Docker Desktop là một ứng dụng dễ dàng cài đặt cho môi trường Mac, Windows hoặc Linux that enables you to build and share containerized applications and microservices. mà cho phép bạn xây dựng và chia sẻ các ứng dụng và microservice được đóng gói trong container.\nDocker registries: Docker registry chứa Docker images. Docker Hub là một công cộng mà mọi người có thể dùng, và Docker mặc định tìm kiếm images trên Docker Hub.\nImages: Một image là một bản mẫu chỉ đọc với các hướng dẫn cho việc tạo một Docker container.\nContainers: Container là một phiên bản có thể triển khai của image. Bạn có thể tạo, khởi chạy, dừng, di chuyển hoặc xóa một container bằng cách sử dụng Docker API hoặc CLI.\nTruy cập Docker docs để thêm thông tin.\n\rNội dung  3.1 Cài đặt Docker 3.2 Tạo Dockerfile cho ứng dụng 3.3 Tạo container image cho ứng dụng 3.4 Triển khai ứng dụng với Docker  "
},
{
	"uri": "/vi/3-deployappwithdocker/3.3-createdockerimage/",
	"title": "Tạo container image",
	"tags": [],
	"description": "",
	"content": "Bạn vừa tạo Dockerfile - để hướng dẫn Docker cách thức xây dựng container image cho ứng dụng của bạn và .dockerignore - để thể hiện cho Docker biết tài nguyên nào không cần phải sao chép lên vùng làm việc. Giờ đây, chúng ta sẽ tiến hành xây dựng container image từ các tệp Dockerfile và .dockerignore.\nTrước khi xây dựng container image. Hãy kiểm tra xem có image nào bên trong máy chủ, nhưng trước tiên hãy kiểm tra process đang chạy trước.\nKiểm tra process  Nhập câu lệnh sau để liệt kê các process đang chạy.  docker ps Không có process nào đang chạy bên trong máy chủ của bạn. Giờ chúng ta sẽ kiểm tra process nào tồn tại bên trong máy chủ. 2. Nhập câu lệnh sau để liệt kê các process tồn tại.\ndocker ps -a Có 2 process đang tồn tại nhưng trạng thái là Exited. Nghĩa là các process này đã dừng. Hãy xóa chúng ra khỏi máy chủ. 3. Nhập ccâu lệnh sau để xóa tất cả process đang tồn tại.\ndocker rm $(docker ps -aq) Kiểm tra lại lần nữa.  docker ps -a Không còn process nào tồn tại\nKiểm tra container image  Nhập câu lệnh sau để liệt kê các image bên trong máy chủ của bạn.  docker images Có một container image tên hello-world. Đây là image được tải xuống khi bạn kiểm thử Docker Engine tại bước 3.1 Install Docker bằng câu lệnh sudo docker run hello-world.\nGiờ chúng ta sẽ xóa image này.  docker delete image hello-word Liệt kê tất cả image một lần nữa.  docker images Bây giờ không còn image nào bên trong máy chủ. Hãy xây dựng container image cho ứng dụng của bạn.\nXây dựng container image  Thực thi câu lệnh này để xây dựng contianer image.  docker build -t fcj-application:v1 . Bây giờ, hãy liệt kê tất cả image trong máy chủ.  docker images Container image của ứng dụng của bạn đã được xây dựng thành công\n"
},
{
	"uri": "/vi/4-interactpcr/",
	"title": "Thao tác với Public Container Registry",
	"tags": [],
	"description": "",
	"content": "Tổng quan A Public Container Registry (PCR) là một công cụ để lưu trữ, tạo phiên bản và phân phối container image một cách công khai trong các kho lưu trữ. DockerHub là một trong số đó và được sử dụng miễn phí. Trong bài thực hành này, chúng ta sẽ sử dụng DockerHub cho Public Container Registry.\nNội dung  4.1 Tạo tài khoản DockerHub 4.2 Đẩy container image lên DockerHub 4.3 Tải container image từ Docker  "
},
{
	"uri": "/vi/3-deployappwithdocker/3.4-deployapp/",
	"title": "Triển khai ứng dụng",
	"tags": [],
	"description": "",
	"content": "Ở bước trước đó, bạn đã xây dựng container image cho ứng dụng của bạn. Bây giờ, chứng ta sẽ triển khai nó lên Docker.\nTriển khai ứng dụng lên Docker sử dụng container image  Thực thi câu lệnh này để khởi chạy ứng dụng của bạn với Docker.  docker run -d --name my-docker-deployment -p 8080:8080 fcj-application:v1 Kiểm tra process đang chạy bên trong máy chủ.  docker ps -a Truy cập URL http://\u0026lt;YOUR_IP_ADDRESS\u0026gt;:8080 để kiểm tra kết quả.   Chúc mừng, bạn vừa triển khai ứng dụng lên Docker thành công. Xóa process.  Đầu tiên, chúng ta cần dừng process đang chạy.  docker stop my-docker-deployment Sau đó, sử dụng câu lệnh này để xóa process.  docker rm my-docker-deployment Kiểm tra các process tồn tại trên máy của bạn lần nữa.  docker ps -a "
},
{
	"uri": "/vi/2-prerequiste/2.4-createbasicapp/",
	"title": "Tạo ứng dụng đơn giản",
	"tags": [],
	"description": "",
	"content": "Ở bước này, chúng ta sẽ tạo một ứng dụng đơn giản sử dụng NodeJS và Express framework.\n Tại Cloud9 terminal, nhập dòng lệnh bên dưới để tạo thư mục cho ứng dụng.  mkdir app\rcd app Khởi tạo ứng dụng.  npm init Nhấn Enter để bỏ qua các bước và xác nhận Yes để kết thúc.  Tạo một tệp tên index.js.  touch index.js Mở tệp index.js và thực hiện mã code.  import express from \u0026#39;express\u0026#39;  const app = express()  app.get(\u0026#39;/\u0026#39;,(req, res) =\u0026gt; {  res.json(\u0026#34;Hello world from FCJ Workshop V1!\u0026#34;) })  app.listen(8080, ()=\u0026gt; {  console.log(\u0026#34;application running on 8080\u0026#34;) }) Lưu tệp và khởi chạy ứng dụng.  node index.js  Nhưng bạn sẽ gặp lỗi bên dưới.   Để giải quyết, mở tệp package.json và thêm định nghĩa bên dưới. Sau đó lưu lại\n  \u0026#34;type\u0026#34;:\u0026#34;module\u0026#34;, Bây giờ, chạy lại ứng dụng.  node index.js Ứng dụng của bạn đã chạy trên cổng 8080.   Bây giờ, chúng ta cần truy cập vào ứng dụng để thấy kết quả. 12. Nhấn Share. 13. Sao chép IP Address ở mục Application. Truy cập ứng dụng bằng URL http://\u0026lt;REPLACE_YOUR_IP\u0026gt;:8080. Ứng dụng của bạn không thể truy cập.   Nguyên nhân và bởi vì security group của máy chủ làm việc vẫn chưa mở cổng 8080 16. Nhấn vào biểu tượng R và chọn Manage EC2 Instance để trở lại máy chủ làm việc. Tại trang Instances, chọn máy chủ làm việc của bạn. Chuyển sang mục Security. Nhấn Security Group.   Tại trang Inbound rules, bạn có thể thấy chưa có quy tắc nào được định nghĩa. 20. Nhấn Edit inbound rules. 21. Tại trang Edit inbound rules, nhấn Add rule. 22. Định nghĩa quy tắc với thông số:\n Type là Custom TCP. Port range là 8080. Source là Anywhere-IPv4.   Sau đó, nhấn Save rules.   Bây giờ, hãy truy cập lại ứng dụng và kiểm tra kết quả.   Chúc mừng, ứng dụng đã hoạt động. "
},
{
	"uri": "/vi/5-deploytok8s/",
	"title": "Triển khai ứng dụng với K8S",
	"tags": [],
	"description": "",
	"content": "Tổng quan Kubernetes là một nền tảng nguồn mở, có thể mở rộng, di động để quản lý khối lượng công việc và dịch vụ được đóng gói, tạo điều kiện thuận lợi cho cả cấu hình khai báo và tự động hóa. Nó có một hệ sinh thái rộng lớn và phát triển nhanh chóng. Các dịch vụ, hỗ trợ và công cụ của Kubernetes có sẵn rộng rãi.\nKiến trúc cụm Kubernetes Cluster: Kubernetes Cluster bao gồm một tập hợp các worker node, được gọi là node, chạy các ứng dụng được đóng gói. Mỗi cụm có ít nhất một worker node.\nControl Plane: Control Plane quản lý các worker node và Pod trong Cluster. Trong môi trường sản phẩm, Control Plane thường hoạt động trên nhiều máy chủ và một cluster thường có nhiều node để đảm bảo tính sẵn sàng và khả nằng chịu lỗi cao.\nWorker Nodes: Work Node chứa các Pods là các thành phần của khối lượng công việc ứng dụng.\nkube-api-server: The API server là một thành phần của Kubernetes control plane mà hiển thị Kubernetes API. Máy chủ API là giao diện cho Kubernetes control plane.\netcd: Bộ lưu trữ key-value nhất quán và khả dụng cao được sử dụng như kho lưu trữ hổ trợ Kubernetes cho tất cả dữ liệu của Cluster. Scheduler: Là thành phần của Control plane giám sát các Pod mới tạo chưa được chỉ định nào node nào, và sẽ chọn một node phù hợp để chúng triển khai trên.\nController Manager: Là thành phần của Control plane chạy các quy trình quản lý. Một cách hợp lý, mỗi bộ điều khiển sẽ là một quy trình riêng biệt nhưng để giảm sự phức tạp, chúng thường được biên dịch thành một tện nhị phân duy nhất để chạy trên một quy trình duy nhất. Có nhiều loại bộ điều khiển khác nhau. Một số ví dụ như:\n Node controller: Chịu trách nhiệm nhận diện và phản hổi khi node không hoạt động. Job controller: Theo dõi các đối tượng Công việc đại diện cho các nhiệm vụ một lần, sau đó tạo các Pod để chạy các nhiệm vụ đó cho đến khi hoàn thành EndpointSlice controller: Điền vào các đối tượng EndpointSlice (để cung cấp liên kết giữa Service và Pod) ServiceAccount controller: Tạo ServiceAccounts mặc định cho một namespace mới.  Trên đây không phải là danh sách đầy đủ.\nkubelet: Một agent chạy trên mỗi node trong cluster. It makes sure that containers are running in a Pod. Nó đảm bảo rằng các container đang chạy trong Pod.\nkube-proxy: kube-proxy là một proxy mạng chạy trên mỗi node trong cluster của bạn, triển khai một phần khái niệm Service Kubernetes.\npod: là một phiên bản duy nhất của một ứng dụng và đối tượng nhỏ nhất mà bạn có thể tạo trong Kubernetes.\nContainer Runtime Interface (CRI): Một thành phần cơ bản hỗ trợ Kubernetes chạy các container một cách hiệu quả. Nó chịu trách nhiệm quản lý việc thực thi và vòng đời của các container trong môi trường Kubernetes.\ncloud-control-manager: Một thành phần Kubernetes control plane nhúng bộ điều khiển dành riêng cho đám mây. Trình quản lý bộ điều khiển đám mây cho phép bạn liên kết cụm của mình với API của nhà cung cấp đám mây và tách các thành phần tương tác với nền tảng đám mây đó khỏi các thành phần chỉ tương tác với cụm của bạn.\nTruy cập Kubernetes docs để thêm thông tin.\n\rNội dung  5.1 Cài đặt Kubernetes 5.2 Triển khai ứng dụng với Kubernetes POD bằng kubectl 5.3 Triển khai ứng dụng với kubernetes POD bằng YAML manifest file  "
},
{
	"uri": "/vi/6-deploytoeks/",
	"title": "Triển khai ứng dụng lên EKS Cluster",
	"tags": [],
	"description": "",
	"content": "Tổng quan Amazon Elastic Kubernetes Service (Amazon EKS) là một dịch vụ được quản lý giúp loại bỏ sự cần thiết của việc cài đặt, vận hành và duy trì Kubernetes control plane của bạn trên Amazon Web Services (AWS).\nKiến trúc Amazon EKS Amazon EKS đảm bảo mỗi cluster đều có Kubernetes control plane riêng biệt. Thiết kế này giữ cho cơ sở hạ tầng của mỗi cụm tách biệt, không trùng lập giữa các Cluster hoặc tài khoản AWS. Việc thiết lập bao gồm:\n Các thành phần phân tán: Control plane chứa ít nhất 2 phiên bản máy chủ API (API server) và 3 phiên bản etcd giữa 3 AWS Availability Zone trong một AWS Region. Tối ưu hiệu suất: Amazon EKS giám sát chủ động và điều chỉnh các phiên bản Control plane để duy trì hiệu năng cao nhất. Khả năng phục hồi: Nếu một phiên bản Control plane không hoạt động, Amazon EKS nhanh chóng thay thế nó, sử dụng Availability Zone khác nếu cần thiết. Thời gian hoạt động ổn định: Bằng việc triển khai các Cluster giữa các Availability Zone, đạt được tính khả dụng của điểm cuối máy chủ API (SLA) đáng tin cậy.  Amazon EKS sử dụng Amazon Virtual Private Cloud (Amazon VPC) để giới hạn lưu lượng giữa các thành phần Control plane bên trong một Cluster. Các thành phần Cluster không thể nhìn thấy hoặc nhận giap tiếp từ các Cluster hoặc tài khoản AWS khác, ngoại trừ khi được xác thực bởi quy tắc Kubernetes role-based access control (RBAC).\nNgoài Control plane, một Amazon EKS cluster còn có một tập các worker machines gọi là node. Việc lựa chọn lại Amazon EKS cluster node thích hợp là rất quan trọng để đáp ứng các yêu cầu cụ thể của bạn và tối ưu hóa việc sử dụng tài nguyên. Amazon EKS cung cấp các loại node chính sau:\n AWS Fargate: Fargate là công cụ điện toán serverless dành cho vùng chứa giúp loại bỏ nhu cầu quản lý các phiên bản cơ bản. Với Fargate, bạn chỉ định nhu cầu tài nguyên của ứng dụng và AWS sẽ tự động cung cấp, thay đổi quy mô và duy trì cơ sở hạ tầng. Tùy chọn này lý tưởng cho những người dùng ưu tiên tính dễ sử dụng và muốn tập trung vào phát triển và triển khai ứng dụng thay vì quản lý cơ sở hạ tầng. Karpenter: Karpenter là một công cụ tự động chia tỷ lệ Kubernetes Cluster linh hoạt, hiệu suất cao, giúp cải thiện tính khả dụng của ứng dụng và hiệu quả của cụm. Karpenter khởi chạy các tài nguyên điện toán có kích thước phù hợp để đáp ứng nhu cầu tải ứng dụng thay đổi. Tùy chọn này có thể cung cấp tài nguyên điện toán kịp thời đáp ứng yêu cầu khối lượng công việc của bạn. Managed node groups: Managed node groups là sự kết hợp giữa tự động hóa và tùy chỉnh để quản lý tập hợp phiên bản Amazon EC2 trong Amazon EKS cluster. AWS đảm nhiệm các nhiệm vụ như vá lỗi, cập nhật và thay đổi quy mô node, giúp đơn giản hóa các khía cạnh vận hành. Song song đó, các đối số kubelet tùy chỉnh được hỗ trợ, mở ra khả năng cho các chính sách quản lý bộ nhớ và CPU nâng cao. ơn nữa, chúng còn tăng cường bảo mật thông qua vai trò AWS Identity and Access Management (IAM) cho các tài khoản dịch vụ, đồng thời hạn chế nhu cầu về các quyền riêng biệt cho mỗi cluster. Self-managed nodes: Self-managed nodes cung cấp toàn quyền kiểm soát các phiên bản Amazon EC2 của bạn trong Amazon EKS cluster. Bạn chịu trách nhiệm quản lý, mở rộng quy mô và duy trì các node, mang lại cho bạn toàn quyền kiểm soát cơ sở hạ tầng cơ bản. Tùy chọn này phù hợp với những người dùng cần kiểm soát và tùy chỉnh chi tiết các node của họ và sẵn sàng đầu tư thời gian vào việc quản lý và duy trì cơ sở hạ tầng của họ.   Truy cập Amazon EKS docs để thêm thông tin.\n\rNội dung  6.1 Cài đặt eksclt 6.2 Triển khai ứng dụng bằng EKS Cluster Managed nodegroup  "
},
{
	"uri": "/vi/7-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dọn dẹp EKS Cluster  Thực thi câu lệnh dưới đây để xóa EKS Cluster  eksctl delete cluster --name my-fcj-cluster --region ap-southeast-1 Sẽ mất khoảng 20 phút để xóa hoàn toàn EKS Cluster.\n\rXóa môi trường Cloud9  Đi đến Cloud9. Chọn FCJ-Workspace. Nhấn Delete.  Nhập Delete để xác nhận. Nhấn Delete.   Xóa IAM Role.   Đi đến IAM Role.\n  Tìm kiếm IAM Role tên eksworkspace-administrator.\n  Chọn IAM Role.\n  Nhấn Delete.   Nhập tên của IAM Role eksworkspace-administrator để xác nhận.\n  Nhấn Delete.   "
},
{
	"uri": "/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]